#! /Applications/Nuke13.0v3/Nuke13.0v3.app/Contents/MacOS/libnuke-13.0.3.dylib -nx
version 13.0 v3
define_window_layout_xml {<?xml version="1.0" encoding="UTF-8"?>
<layout version="1.0">
    <window x="281" y="291" w="1907" h="1148" screen="0">
        <splitter orientation="1">
            <split size="40"/>
            <dock id="" hideTitles="1" activePageId="Toolbar.1">
                <page id="Toolbar.1"/>
            </dock>
            <split size="1244" stretch="1"/>
            <splitter orientation="2">
                <split size="662"/>
                <dock id="" activePageId="Viewer.1">
                    <page id="Viewer.1"/>
                </dock>
                <split size="466"/>
                <dock id="" activePageId="DAG.1" focus="true">
                    <page id="DAG.1"/>
                    <page id="Curve Editor.1"/>
                    <page id="DopeSheet.1"/>
                </dock>
            </splitter>
            <split size="615"/>
            <splitter orientation="2">
                <split size="564"/>
                <dock id="" activePageId="Properties.1">
                    <page id="Properties.1"/>
                    <page id="uk.co.thefoundry.backgroundrenderview.1"/>
                </dock>
                <split size="564"/>
                <dock id="" activePageId="uk.co.thefoundry.scripteditor.1">
                    <page id="uk.co.thefoundry.scripteditor.1"/>
                </dock>
            </splitter>
        </splitter>
    </window>
</layout>
}
Root {
 inputs 0
 name /Users/afry/GitHub/hellwig2022/hellwig2022.nk
 frame 6
 format "2048 1556 0 0 2048 1556 1 2K_Super_35(full-ap)"
 proxy_type scale
 proxy_format "1024 778 0 0 1024 778 1 1K_Super_35(full-ap)"
 colorManagement Nuke
 OCIO_config custom
 customOCIOConfigPath /Users/afry/Documents/GitHub/OpenColorIO-Configs/aces_1.2/config.ocio
 workingSpaceLUT linear
 monitorLut sRGB
 monitorOutLUT rec709
 int8Lut sRGB
 int16Lut sRGB
 logLut Cineon
 floatLut linear
}
StickyNote {
 inputs 0
 name StickyNote1
 label "Converts from XYZ to Fairchild-Hellwig2022 JMh\n(and back)"
 xpos 181
 ypos 6
}
ColorWheel {
 inputs 0
 gamma 0.45
 name ColorWheel1
 xpos 427
 ypos -88
}
set N1f781800 [stack 0]
Ramp {
 inputs 0
 output {rgba.red -rgba.green -rgba.blue rgba.alpha}
 p0 {0 0}
 p1 {0 1556}
 color 8
 name Ramp1
 xpos 528
 ypos -44
}
Ramp {
 output {-rgba.red -rgba.green rgba.blue rgba.alpha}
 p0 {0 0}
 p1 {2048 0}
 color 360
 name Ramp2
 xpos 528
 ypos -12
}
Shuffle2 {
 fromInput1 {{0} B}
 fromInput2 {{0} B}
 mappings "4 rgba.red 0 0 rgba.red 0 0 white -1 -1 rgba.green 0 1 rgba.blue 0 2 rgba.blue 0 2 rgba.alpha 0 3 rgba.alpha 0 3"
 name Shuffle1
 xpos 528
 ypos 20
}
Multiply {
 channels {-rgba.red rgba.green -rgba.blue}
 value {{frame-1}}
 name Multiply1
 xpos 528
 ypos 44
}
BlinkScript {
 kernelSourceFile /Users/afry/GitHub/hellwig2022/hellwig2022.blink
 recompileCount 251
 ProgramGroup 1
 KernelDescription "2 \"hellwig2022\" iterate pixelWise e61ba9f246a6b79db1f7d548e2d7d9671fb5a58c7be502922ad28c704879b04e 2 \"src\" Read Point \"dst\" Write Point 6 \"direction\" Int 1 AAAAAA== \"XYZ_w\" Float 3 AAAAAAAAAAAAAAAAAAAAAA== \"L_A\" Float 1 AAAAAA== \"Y_b\" Float 1 AAAAAA== \"surround\" Float 3 AAAAAAAAAAAAAAAAAAAAAA== \"discount_illuminant\" Bool 1 AA== 6 \"direction\" 1 1 \"XYZ_w\" 3 1 \"L_A\" 1 1 \"Y_b\" 1 1 \"surround\" 3 1 \"discount_illuminant\" 1 1 3 \"HALF_MIN\" Float 1 1 AAAAAA== \"HALF_MAX\" Float 1 1 AAAAAA== \"CAT_CAT16\" Float 9 1 AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA"
 kernelSource "\nkernel hellwig2022 : ImageComputationKernel<ePixelWise>\n\{\n  Image<eRead, eAccessPoint, eEdgeClamped> src; // the input image\n  Image<eWrite> dst; // the output image\n\n  param:\n\n    // the kernel parameters\n    int direction; // the direction of the convolution\n\n    float3 XYZ_w;\n    float L_A;\n    float Y_b;\n    float3 surround;\n    bool discount_illuminant;\n\n\n  local:\n    float HALF_MIN;\n    float HALF_MAX;\n\n    float3x3 CAT_CAT16;\n\n\n  void define()\n  \{\n\n  \}\n\n  // multiplies a 3D vector with a 3x3 matrix\n  float3 vector_dot( float3x3 m, float3 v)\n  \{\n    float3 r = 1.0f;\n    for(int c = 0; c<3; c++)\n    \{\n      r\[c] = m\[c]\[0]*v.x + m\[c]\[1]*v.y + m\[c]\[2]*v.z;\n    \}\n\n    return r;\n  \}\n\n  // linear interpolation between two values a & b with the bias t\n  float lerp(float a, float b, float t)\n  \{\n    return a + t * (b - a);\n  \}\n\n        // \"safe\" power function to avoid NANs or INFs when taking a fractional power of a negative base\n    // this one initially returned -pow(abs(b), e) for negative b\n    // but this ended up producing undesirable results in some cases\n    // so now it just returns 0.0 instead\n    float spow( float base, float exponent )\n    \{\n        if(base < 0.0f && exponent != floor(exponent) )\n        \{\n        return 0.0f;\n        \}\n        else\n        \{\n        return pow(base, exponent); \n        \}\n    \}\n\n    float3 float3spow( float3 base, float exponent )\n    \{\n        return float3(spow(base.x, exponent), spow(base.y, exponent), spow(base.z, exponent));\n    \}\n\n    float3 float3sign( float3 v )\n    \{\n        return float3(sign(v.x), sign(v.y), sign(v.z));\n    \}\n\n\n    // \"safe\" div\n    float sdiv( float a, float b )\n    \{\n        if(b == 0.0f)\n        \{\n        return 0.0f;\n        \}\n        else\n        \{\n        return a / b;\n        \}\n    \}\n    \n\n    // convert radians to degrees\n    float degrees( float radians )\n    \{\n      return radians * 180.0f / PI;\n    \}\n\n    float abs( float a )\n    \{\n      return fabs(a);\n    \}\n\n    float3 float3abs( float3 a )\n    \{\n      return fabs(a);\n    \}\n  \n\n  // get the y value of f(x) where the fuction is defined as a line between two points\n  // the two points as passed as an array \[a.x, a.y, b.x, b.y]\n  float lerp1D( float4 table, float x)\n  \{\n    float m = (table.w-table.y) / (table.z-table.x);\n    float c = table.y - (m*table.x);\n    float y = x*m+c;\n    return y;\n  \}\n\n  float3 float3_to_domain_100( float3 v )\n  \{\n    return v;\n  \}\n  \n\n\n  float hue_angle( float a, float b )\n  \{\n    // \"\"\"\n    // Return the *hue* angle :math:`h` in degrees.\n\n    // Parameters\n    // ----------\n    // a\n    //     Opponent colour dimension :math:`a`.\n    // b\n    //     Opponent colour dimension :math:`b`.\n\n    // Returns\n    // -------\n    // :class:`numpy.floating` or :class:`numpy.ndarray`\n    //     *Hue* angle :math:`h` in degrees.\n\n    // Examples\n    // --------\n    // >>> a = -0.000624112068243\n    // >>> b = -0.000506270106773\n    // >>> hue_angle(a, b)  # doctest: +ELLIPSIS\n    // 219.0484326...\n    // \"\"\"\n\n    // a = as_float_array(a);\n    // b = as_float_array(b);\n\n    float h = degrees(atan2(b, a)) / 360;\n\n    return h;\n  \}\n\n  float clip(float x, float a, float b)\n  \{\n    return max(a, min(x, b));\n  \}\n\n  float mod(float a, float N)\n  \{\n    return a - N*floor(a/N);\n  \} \n\n  float radians(float a)\n  \{\n    return a * PI / 180.0f;\n  \}\n\n  float achromatic_response_forward(float3 RGB)\n  \{\n    //   \"\"\"\n    //   Return the achromatic response :math:`A` from given compressed\n    //   *CAM16* transform sharpened *RGB* array and :math:`N_\{bb\}` chromatic\n    //   induction factor for forward *Hellwig and Fairchild (2022)* implementation.\n\n    //   Parameters\n    //   ----------\n    //   RGB\n    //       Compressed *CAM16* transform sharpened *RGB* array.\n\n    //   Returns\n    //   -------\n    //   :class:`numpy.floating` or :class:`numpy.ndarray`\n    //       Achromatic response :math:`A`.\n\n    //   Examples\n    //   --------\n    //   >>> RGB = np.array(\[7.94634384, 7.94713791, 7.9488967])\n    //   >>> achromatic_response_forward(RGB)  # doctest: +ELLIPSIS\n    //   23.9322704...\n    //   \"\"\"\n\n    float R = RGB.x;\n    float G = RGB.y;\n    float B = RGB.z;\n\n\n    float A = 2 * R + G + 0.05 * B - 0.305;\n\n    return A;\n  \}\n\n  float colourfulness_correlate(float N_c,float e_t,float a,float b) \n  \{\n    // \"\"\"\n    // Return the *colourfulness* correlate :math:`M`.\n\n    // Parameters\n    // ----------\n    // N_c\n    //     Surround chromatic induction factor :math:`N_\{c\}`.\n    // e_t\n    //     Eccentricity factor :math:`e_t`.\n    // a\n    //     Opponent colour dimension :math:`a`.\n    // b\n    //     Opponent colour dimension :math:`b`.\n\n    // Returns\n    // -------\n    // :class:`numpy.floating` or :class:`numpy.ndarray`\n    //     *Colourfulness* correlate :math:`M`.\n\n    // Examples\n    // --------\n    // >>> N_c = 1\n    // >>> e_t = 1.13423124867\n    // >>> a = -0.00063418423001\n    // >>> b = -0.000479072513542\n    // >>> colourfulness_correlate(N_c, e_t, a, b)  # doctest: +ELLIPSIS\n    // 0.0387637...\n    // \"\"\"\n\n    // N_c = as_float_array(N_c)\n    // e_t = as_float_array(e_t)\n    // a = as_float_array(a)\n    // b = as_float_array(b)\n\n    float M = 43 * N_c * e_t * sqrt(pow(a,2) + pow(b,2));\n\n    return M;\n  \}\n\n\n\n  float degree_of_adaptation(float  F, float L_A )\n    \{\n    // \"\"\"\n    // Return the degree of adaptation :math:`D` from given surround maximum\n    // degree of adaptation :math:`F` and adapting field *luminance* :math:`L_A`\n    // in :math:`cd/m^2`.\n\n    // Parameters\n    // ----------\n    // F\n    //     Surround maximum degree of adaptation :math:`F`.\n    // L_A\n    //     Adapting field *luminance* :math:`L_A` in :math:`cd/m^2`.\n\n    // Returns\n    // -------\n    // :class:`numpy.floating` or :class:`numpy.ndarray`\n    //     Degree of adaptation :math:`D`.\n\n    // Examples\n    // --------\n    // >>> degree_of_adaptation(1.0, 318.31)  # doctest: +ELLIPSIS\n    // 0.9944687...\n    // \"\"\"\n\n    // F = as_float_array(F)\n    // L_A = as_float_array(L_A)\n\n    float D = F * (1 - (1 / 3.6) * exp((-L_A - 42) / 92));\n\n    return D;\n    \}\n\n\n  float3 XYZ_to_Hellwig2022_JMh( float3 XYZ, float3 XYZ_w, float L_A, float Y_b, float3 surround, bool discount_illuminant)\n    \{\n//     \"\"\"\n//     Compute the *Hellwig and Fairchild (2022)* colour appearance model\n//     correlates from given *CIE XYZ* tristimulus values.\n\n//     Parameters\n//     ----------\n//     XYZ\n//         *CIE XYZ* tristimulus values of test sample / stimulus.\n//     XYZ_w\n//         *CIE XYZ* tristimulus values of reference white.\n//     L_A\n//         Adapting field *luminance* :math:`L_A` in :math:`cd/m^2`, (often taken\n//         to be 20% of the luminance of a white object in the scene).\n//     Y_b\n//         Luminous factor of background :math:`Y_b` such as\n//         :math:`Y_b = 100 x L_b / L_w` where :math:`L_w` is the luminance of the\n//         light source and :math:`L_b` is the luminance of the background. For\n//         viewing images, :math:`Y_b` can be the average :math:`Y` value for the\n//         pixels in the entire image, or frequently, a :math:`Y` value of 20,\n//         approximate an :math:`L^*` of 50 is used.\n//     surround\n//         Surround viewing conditions induction factors.\n//     discount_illuminant\n//         Truth value indicating if the illuminant should be discounted.\n\n//     Returns\n//     -------\n//     :class:`colour.CAM_Specification_Hellwig2022`\n//         *Hellwig and Fairchild (2022)* colour appearance model specification.\n\n//     Notes\n//     -----\n//     +------------+-----------------------+---------------+\n//     | **Domain** | **Scale - Reference** | **Scale - 1** |\n//     +============+=======================+===============+\n//     | ``XYZ``    | \[0, 100]              | \[0, 1]        |\n//     +------------+-----------------------+---------------+\n//     | ``XYZ_w``  | \[0, 100]              | \[0, 1]        |\n//     +------------+-----------------------+---------------+\n\n//     +-------------------------------------+-----------------------+-----------\\\n// ----+\n//     | **Range**                           | **Scale - Reference** | **Scale - \\\n// 1** |\n//     +=====================================+=======================+===========\\\n// ====+\n//     | ``CAM_Specification_Hellwig2022.J`` | \[0, 100]              | \[0, 1]    \\\n//     |\n//     +-------------------------------------+-----------------------+-----------\\\n// ----+\n//     | ``CAM_Specification_Hellwig2022.C`` | \[0, 100]              | \[0, 1]    \\\n//     |\n//     +-------------------------------------+-----------------------+-----------\\\n// ----+\n//     | ``CAM_Specification_Hellwig2022.h`` | \[0, 360]              | \[0, 1]    \\\n//     |\n//     +-------------------------------------+-----------------------+-----------\\\n// ----+\n//     | ``CAM_Specification_Hellwig2022.s`` | \[0, 100]              | \[0, 1]    \\\n//     |\n//     +-------------------------------------+-----------------------+-----------\\\n// ----+\n//     | ``CAM_Specification_Hellwig2022.Q`` | \[0, 100]              | \[0, 1]    \\\n//     |\n//     +-------------------------------------+-----------------------+-----------\\\n// ----+\n//     | ``CAM_Specification_Hellwig2022.M`` | \[0, 100]              | \[0, 1]    \\\n//     |\n//     +-------------------------------------+-----------------------+-----------\\\n// ----+\n//     | ``CAM_Specification_Hellwig2022.H`` | \[0, 400]              | \[0, 1]    \\\n//     |\n//     +-------------------------------------+-----------------------+-----------\\\n// ----+\n\n//     References\n//     ----------\n//     :cite:`Fairchild2022`, :cite:`Hellwig2022`\n\n//     Examples\n//     --------\n//     >>> XYZ = np.array(\[19.01, 20.00, 21.78])\n//     >>> XYZ_w = np.array(\[95.05, 100.00, 108.88])\n//     >>> L_A = 318.31\n//     >>> Y_b = 20.0\n//     >>> surround = VIEWING_CONDITIONS_Hellwig2022\['Average']\n//     >>> XYZ_to_Hellwig2022(XYZ, XYZ_w, L_A, Y_b, surround)\n//     ... # doctest: +ELLIPSIS\n//     CAM_Specification_Hellwig2022(J=41.7312079..., C=0.0257636..., \\\n// h=217.0679597..., s=0.0608550..., Q=55.8523226..., M=0.0339889..., \\\n// H=275.5949861..., HC=None)\n//     \"\"\"\n\n    XYZ = float3_to_domain_100(XYZ);\n    XYZ_w = float3_to_domain_100(XYZ_w);\n    float _X_w = XYZ_w.x ;\n    float Y_w = XYZ_w.y ;\n    float _Z_w = XYZ_w.z ;\n    // L_A = as_float_array(L_A)\n    // Y_b = as_float_array(Y_b)\n\n    // # Step 0\n    // # Converting *CIE XYZ* tristimulus values to sharpened *RGB* values.\n    float3x3 MATRIX_16 = CAT_CAT16;\n    float3 RGB_w = vector_dot(MATRIX_16, XYZ_w);\n\n    // # Computing degree of adaptation :math:`D`.\n    float D = clip(degree_of_adaptation(surround.x, L_A), 0, 1);\n    if(discount_illuminant)\n    \{\n        D = 1.0f;\n    \}\n\n\n    // # Viewing conditions dependent parameters\n    float k = 1 / (5 * L_A + 1);\n    float k4 = pow(k,4);\n    float F_L = 0.2f * k4 * (5.0f * L_A) + 0.1f * pow((1.0f - k4), 2.0f) * spow(5.0f * L_A, 1.0f / 3.0f) ;\n    float n = sdiv(Y_b, Y_w);\n    float z = 1.48 + sqrt(n);\n\n    // // float D_RGB = ( D\[..., np.newaxis] * Y_w\[..., np.newaxis] / RGB_w + 1 - D\[..., np.newaxis] )\n    float3 D_RGB = D * Y_w / RGB_w + 1 - D;\n    float3 RGB_wc = D_RGB * RGB_w;\n    \n    // # Applying forward post-adaptation non-linear response compression.\n    // F_L_RGB = spow(F_L\[..., np.newaxis] * np.absolute(RGB_wc) / 100, 0.42)\n    float3 F_L_RGB = float3spow(F_L * float3abs(RGB_wc) / 100.0f, 0.42f);\n\n    // # Computing achromatic responses for the whitepoint.\n    // RGB_aw = (400 * np.sign(RGB_wc) * F_L_RGB) / (27.13 + F_L_RGB) + 0.1\n    float3 RGB_aw = (400.0f * float3sign(RGB_wc) * F_L_RGB) / (27.13f + F_L_RGB) + 0.1f;\n\n    // # Computing achromatic responses for the whitepoint.\n    // R_aw, G_aw, B_aw = tsplit(RGB_aw)\n    float R_aw = RGB_aw.x ;\n    float G_aw = RGB_aw.y ;\n    float B_aw = RGB_aw.z ;\n    // A_w = 2 * R_aw + G_aw + 0.05 * B_aw - 0.305\n    float A_w = 2 * R_aw + G_aw + 0.05f * B_aw - 0.305f;\n\n    // # Step 1\n    // # Converting *CIE XYZ* tristimulus values to sharpened *RGB* values.\n    // RGB = vector_dot(MATRIX_16, XYZ)\n    float3 RGB = vector_dot(MATRIX_16, XYZ);\n\n    // # Step 2\n    // RGB_c = D_RGB * RGB\n    float3 RGB_c = D_RGB * RGB;\n\n    // # Step 3\n    // # Applying forward post-adaptation non-linear response compression.\n    // F_L_RGB = spow(F_L\[..., np.newaxis] * np.absolute(RGB_c) / 100, 0.42)\n    float3 F_L_RGB_2 = float3spow(F_L * float3abs(RGB_c) / 100.0f, 0.42f);\n    // RGB_a = (400 * np.sign(RGB_c) * F_L_RGB) / (27.13 + F_L_RGB) + 0.1\n    float3 RGB_a = (400.0f * float3sign(RGB_c) * F_L_RGB_2) / (27.13f + F_L_RGB_2) + 0.1f;\n\n\n    // # Step 4\n    // # Converting to preliminary cartesian coordinates.\n    // R_a, G_a, B_a = tsplit(RGB_a)\n    float R_a = RGB_a.x ;\n    float G_a = RGB_a.y ;\n    float B_a = RGB_a.z ;\n    // a = R_a - 12 * G_a / 11 + B_a / 11\n    float a = R_a - 12.0f * G_a / 11.0f + B_a / 11.0f;\n    // b = (R_a + G_a - 2 * B_a) / 9\n    float b = (R_a + G_a - 2.0f * B_a) / 9.0f;\n\n    // # Computing the *hue* angle :math:`h`.\n    // h = np.degrees(np.arctan2(b, a)) % 360\n    // Unclear why this isnt matching the python version.\n    float h = mod(degrees(atan2(b, a)), 360.0f);\n\n    \n\n    // # Step 5\n    // # Computing eccentricity factor *e_t*.\n    // hr = np.radians(h)\n    float hr = radians(h);\n\n    // _h = hr\n    // _2_h = 2 * hr\n    // _3_h = 3 * hr\n    // _4_h = 4 * hr\n    float _h = hr;\n    float _2_h = 2 * hr;\n    float _3_h = 3 * hr;\n    float _4_h = 4 * hr;\n\n    // e_t = (\n    //     -0.0582 * np.cos(_h)\n    //     - 0.0258 * np.cos(_2_h)\n    //     - 0.1347 * np.cos(_3_h)\n    //     + 0.0289 * np.cos(_4_h)\n    //     - 0.1475 * np.sin(_h)\n    //     - 0.0308 * np.sin(_2_h)\n    //     + 0.0385 * np.sin(_3_h)\n    //     + 0.0096 * np.sin(_4_h)\n    //     + 1\n    // )\n    float e_t = (\n        -0.0582f * cos(_h)\n        - 0.0258f * cos(_2_h)\n        - 0.1347f * cos(_3_h)\n        + 0.0289f * cos(_4_h)\n        - 0.1475f * sin(_h)\n        - 0.0308f * sin(_2_h)\n        + 0.0385f * sin(_3_h)\n        + 0.0096f * sin(_4_h)\n        + 1.0f\n    );\n\n    // # Step 6\n    // # Computing achromatic responses for the stimulus.\n    // R_a, G_a, B_a = tsplit(RGB_a)\n    float R_a2 = RGB_a.x ;\n    float G_a2 = RGB_a.y ;\n    float B_a2 = RGB_a.z ;\n    // A = 2 * R_a + G_a + 0.05 * B_a - 0.305\n    float A = 2 * R_a2 + G_a2 + 0.05f * B_a2 - 0.305f;\n\n    // # Step 7\n    // # Computing the correlate of *Lightness* :math:`J`.\n    // with sdiv_mode():\n    //     J = 100 * spow(sdiv(A, A_w), surround.c * z)\n\n    float J = 100.0f * spow(sdiv(A, A_w), surround.y * z);\n\n    // # Step 8\n    // # Computing the correlate of *brightness* :math:`Q`.\n    // with sdiv_mode():\n    //     Q = (2 / as_float(surround.c)) * (J / 100) * A_w\n    float Q = (2.0f / float(surround.y)) * (J / 100.0f) * A_w;\n\n    // # Step 9\n    // # Computing the correlate of *colourfulness* :math:`M`.\n    // M = 43 * surround.N_c * e_t * np.sqrt(a**2 + b**2)\n    float M = 43.0f * surround.z * e_t * sqrt(a * a + b * b);\n\n    // # Computing the correlate of *chroma* :math:`C`.\n    // with sdiv_mode():\n    //     C = 35 * sdiv(M, A_w)\n    float C = 35.0f * sdiv(M, A_w);\n\n\n    // # Computing the correlate of *saturation* :math:`s`.\n    // with sdiv_mode():\n    //     s = 100 * sdiv(M, Q)\n    float s = 100.0f * sdiv(M, Q);\n\n\n\n    // return XYZ_w;\n    // return RGB_w;\n    // return \{D,k,k4\};\n    // return \{F_L,n,z\};\n    // return RGB_a;\n    return \{J,M,h\};\n    // return XYZ;\n    \}\n\n    float3 Hellwig2022_JMh_to_XYZ( float3 JMh, float3 XYZ_w, float L_A, float Y_b, float3 surround, bool discount_illuminant)\n    \{\n        float J = JMh.x;\n        float M = JMh.y;\n        float h = JMh.z;\n\n        // L_A = as_float_array(L_A)\n        // XYZ_w = to_domain_100(XYZ_w)\n        // _X_w, Y_w, _Z_w = tsplit(XYZ_w)\n        float _X_w = XYZ_w.x;\n        float Y_w = XYZ_w.y;\n        float _Z_w = XYZ_w.z;\n\n        // # Step 0\n        // # Converting *CIE XYZ* tristimulus values to sharpened *RGB* values.\n        // RGB_w = vector_dot(MATRIX_16, XYZ_w)\n        float3x3 MATRIX_16 = CAT_CAT16;\n        float3 RGB_w = vector_dot(MATRIX_16, XYZ_w);\n\n\n        // # Computing degree of adaptation :math:`D`.\n        float D = clip(degree_of_adaptation(surround.x, L_A), 0, 1);\n        if(discount_illuminant)\n        \{\n            D = 1.0f;\n        \}\n\n\n\n        // # Viewing conditions dependent parameters\n        float k = 1 / (5 * L_A + 1);\n        float k4 = pow(k,4);\n        float F_L = 0.2f * k4 * (5.0f * L_A) + 0.1f * pow((1.0f - k4), 2.0f) * spow(5.0f * L_A, 1.0f / 3.0f) ;\n        float n = sdiv(Y_b, Y_w);\n        float z = 1.48 + sqrt(n);\n\n        // // float D_RGB = ( D\[..., np.newaxis] * Y_w\[..., np.newaxis] / RGB_w + 1 - D\[..., np.newaxis] )\n        float3 D_RGB = D * Y_w / RGB_w + 1 - D;\n        float3 RGB_wc = D_RGB * RGB_w;\n        \n        // # Applying forward post-adaptation non-linear response compression.\n        // F_L_RGB = spow(F_L\[..., np.newaxis] * np.absolute(RGB_wc) / 100, 0.42)\n        float3 F_L_RGB = float3spow(F_L * float3abs(RGB_wc) / 100.0f, 0.42f);\n\n        // # Computing achromatic responses for the whitepoint.\n        // RGB_aw = (400 * np.sign(RGB_wc) * F_L_RGB) / (27.13 + F_L_RGB) + 0.1\n        float3 RGB_aw = (400.0f * float3sign(RGB_wc) * F_L_RGB) / (27.13f + F_L_RGB) + 0.1f;\n\n        // # Computing achromatic responses for the whitepoint.\n        // R_aw, G_aw, B_aw = tsplit(RGB_aw)\n        float R_aw = RGB_aw.x ;\n        float G_aw = RGB_aw.y ;\n        float B_aw = RGB_aw.z ;\n        // A_w = 2 * R_aw + G_aw + 0.05 * B_aw - 0.305\n        float A_w = 2 * R_aw + G_aw + 0.05f * B_aw - 0.305f;\n\n        // # Step 2\n        // # Computing eccentricity factor *e_t*.\n        // hr = np.radians(h)\n        float hr = radians(h);\n\n\n        // _h = hr\n        // _2_h = 2 * hr\n        // _3_h = 3 * hr\n        // _4_h = 4 * hr\n        float _h = hr;\n        float _2_h = 2 * hr;\n        float _3_h = 3 * hr;\n        float _4_h = 4 * hr;\n    \n        // e_t = (\n        //     -0.0582 * np.cos(_h)\n        //     - 0.0258 * np.cos(_2_h)\n        //     - 0.1347 * np.cos(_3_h)\n        //     + 0.0289 * np.cos(_4_h)\n        //     - 0.1475 * np.sin(_h)\n        //     - 0.0308 * np.sin(_2_h)\n        //     + 0.0385 * np.sin(_3_h)\n        //     + 0.0096 * np.sin(_4_h)\n        //     + 1\n        // )\n        float e_t = (\n            -0.0582f * cos(_h)\n            - 0.0258f * cos(_2_h)\n            - 0.1347f * cos(_3_h)\n            + 0.0289f * cos(_4_h)\n            - 0.1475f * sin(_h)\n            - 0.0308f * sin(_2_h)\n            + 0.0385f * sin(_3_h)\n            + 0.0096f * sin(_4_h)\n            + 1.0f\n        );\n\n        // # Computing achromatic response :math:`A` for the stimulus.\n        // A = A = A_w * spow(J / 100, 1 / (surround.c * z))\n        float A = A_w * spow(J / 100.0f, 1.0f / (surround.y * z));\n\n        // # Computing *P_p_1* to *P_p_2*.\n        // P_p_1 = 43 * surround.N_c * e_t\n        // P_p_2 = A\n        float P_p_1 = 43.0f * surround.z * e_t;\n        float P_p_2 = A;\n\n\n        // # Step 3\n        // # Computing opponent colour dimensions :math:`a` and :math:`b`.\n        // with sdiv_mode():\n        //     gamma = M / P_p_1\n        float gamma = M / P_p_1;\n    \n        // a = gamma * np.cos(hr)\n        float a = gamma * cos(hr);\n        // b = gamma * np.sin(hr)\n        float b = gamma * sin(hr);\n\n\n        // # Step 4\n        // # Applying post-adaptation non-linear response compression matrix.\n        // RGB_a = (\n        //     vector_dot(\n        //         \[\n        //             \[460, 451, 288],\n        //             \[460, -891, -261],\n        //             \[460, -220, -6300],\n        //         ],\n        //         tstack(\[P_p_2, a, b]),\n        //     )\n        //     / 1403\n        // )\n\n        float panlrcm_data\[]=\n        \{\n            460.0f, 451.0f, 288.0f,\n            460.0f, -891.0f, -261.0f,\n            460.0f, -220.0f, -6300.0f,\n        \};\n        float3x3 panlrcm;\n        panlrcm.setArray(panlrcm_data);\n\n        float3 RGB_a = vector_dot(panlrcm, float3(P_p_2, a, b)) / 1403.0f;\n\n        // # Step 5\n        // # Applying inverse post-adaptation non-linear response compression.\n        // RGB_c = (\n        //     np.sign(RGB_a)\n        //     * 100\n        //     / F_L\[..., np.newaxis]\n        //     * spow(\n        //         (27.13 * np.absolute(RGB_a)) / (400 - np.absolute(RGB_a)),\n        //         1 / 0.42,\n        //     )\n        // )\n        float3 RGB_c = float3sign(RGB_a) * 100.0f / F_L * float3spow((27.13f * float3abs(RGB_a)) / (400.0f - float3abs(RGB_a)), 1.0f / 0.42f);\n\n        // # Step 6\n        // RGB = RGB_c / D_RGB\n        float3 RGB = RGB_c / D_RGB;\n    \n        // # Step 7\n        // XYZ = vector_dot(MATRIX_INVERSE_16, RGB)\n        float3x3 MATRIX_INVERSE_16 = CAT_CAT16.invert();\n        float3 XYZ = vector_dot(MATRIX_INVERSE_16, RGB);\n\n        return XYZ;\n\n    \}\n\n\n  void init()\n  \{\n    HALF_MIN = 0.0000000596046448f;\n    HALF_MAX = 65504.0f;\n\n    float CAT_CAT16_data\[]=\n    \{\n      0.401288, 0.650173, -0.051461,\n      -0.250268, 1.204414, 0.045854,\n      -0.002079, 0.048952, 0.953127,\n    \};\n\n    CAT_CAT16.setArray(CAT_CAT16_data);\n\n  \}\n\n\n  void process()\n  \{\n    SampleType(src) source = src();\n    float3 srcRGB(source.x, source.y, source.z);\n    float3 dstRGB;\n    float3 diagnostic;\n\n    // diagnostic =  srcRGB;\n\n    // float3 surround(1.0f, 0.69f, 1.0f);\n    // float3 XYZ_w(95.05f, 100.00f, 108.88f);\n\n    if (direction == 0)\n    \{\n        float3 JMh = XYZ_to_Hellwig2022_JMh(srcRGB, XYZ_w, L_A, Y_b,surround,discount_illuminant);\n        dstRGB = JMh;\n    \}\n    else\n    \{\n        float3 XYZ_out = Hellwig2022_JMh_to_XYZ(srcRGB, XYZ_w, L_A, Y_b, surround, discount_illuminant);\n        dstRGB = XYZ_out;\n    \}\n\n    diagnostic = dstRGB;\n\n\n    dst() = float4(diagnostic.x, diagnostic.y, diagnostic.z, source.w ); \n  \}\n\};\n"
 rebuild ""
 hellwig2022_direction 1
 hellwig2022_XYZ_w {95.05 100 108.88}
 hellwig2022_L_A 318.31
 hellwig2022_Y_b 20
 hellwig2022_surround {1 0.69 1}
 rebuild_finalise ""
 name BlinkScript2
 xpos 425
 ypos 120
}
Colorspace {
 colorspace_in CIE-XYZ
 primary_out DCI-P3
 name Colorspace2
 xpos 425
 ypos 152
}
Expression {
 channel0 alpha
 expr0 1-max(max(r<0,g<0,b<0),max(r>1,g>1,b>1))
 channel1 none
 expr1 g<0
 channel2 none
 expr2 b<0
 name Expression1
 xpos 425
 ypos 200
}
Premult {
 name Premult1
 xpos 425
 ypos 224
}
Viewer {
 inputs 2
 frame 6
 frame_range 1-100
 colour_sample_bbox {1.4921875 -0.572265625 1.493164062 -0.5712890625}
 samplepoints {{1.018554688 -0.1259765625}
   }
 gl_buffer_depth half-float
 name Viewer1
 xpos 306
 ypos 234
}
push $N1f781800
Colorspace {
 colorspace_out CIE-XYZ
 name Colorspace1
 xpos 427
 ypos -16
}
BlinkScript {
 kernelSourceFile /Users/afry/GitHub/hellwig2022/hellwig2022.blink
 recompileCount 251
 ProgramGroup 1
 KernelDescription "2 \"hellwig2022\" iterate pixelWise e61ba9f246a6b79db1f7d548e2d7d9671fb5a58c7be502922ad28c704879b04e 2 \"src\" Read Point \"dst\" Write Point 6 \"direction\" Int 1 AAAAAA== \"XYZ_w\" Float 3 AAAAAAAAAAAAAAAAAAAAAA== \"L_A\" Float 1 AAAAAA== \"Y_b\" Float 1 AAAAAA== \"surround\" Float 3 AAAAAAAAAAAAAAAAAAAAAA== \"discount_illuminant\" Bool 1 AA== 6 \"direction\" 1 1 \"XYZ_w\" 3 1 \"L_A\" 1 1 \"Y_b\" 1 1 \"surround\" 3 1 \"discount_illuminant\" 1 1 3 \"HALF_MIN\" Float 1 1 AAAAAA== \"HALF_MAX\" Float 1 1 AAAAAA== \"CAT_CAT16\" Float 9 1 AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA"
 kernelSource "\nkernel hellwig2022 : ImageComputationKernel<ePixelWise>\n\{\n  Image<eRead, eAccessPoint, eEdgeClamped> src; // the input image\n  Image<eWrite> dst; // the output image\n\n  param:\n\n    // the kernel parameters\n    int direction; // the direction of the convolution\n\n    float3 XYZ_w;\n    float L_A;\n    float Y_b;\n    float3 surround;\n    bool discount_illuminant;\n\n\n  local:\n    float HALF_MIN;\n    float HALF_MAX;\n\n    float3x3 CAT_CAT16;\n\n\n  void define()\n  \{\n\n  \}\n\n  // multiplies a 3D vector with a 3x3 matrix\n  float3 vector_dot( float3x3 m, float3 v)\n  \{\n    float3 r = 1.0f;\n    for(int c = 0; c<3; c++)\n    \{\n      r\[c] = m\[c]\[0]*v.x + m\[c]\[1]*v.y + m\[c]\[2]*v.z;\n    \}\n\n    return r;\n  \}\n\n  // linear interpolation between two values a & b with the bias t\n  float lerp(float a, float b, float t)\n  \{\n    return a + t * (b - a);\n  \}\n\n        // \"safe\" power function to avoid NANs or INFs when taking a fractional power of a negative base\n    // this one initially returned -pow(abs(b), e) for negative b\n    // but this ended up producing undesirable results in some cases\n    // so now it just returns 0.0 instead\n    float spow( float base, float exponent )\n    \{\n        if(base < 0.0f && exponent != floor(exponent) )\n        \{\n        return 0.0f;\n        \}\n        else\n        \{\n        return pow(base, exponent); \n        \}\n    \}\n\n    float3 float3spow( float3 base, float exponent )\n    \{\n        return float3(spow(base.x, exponent), spow(base.y, exponent), spow(base.z, exponent));\n    \}\n\n    float3 float3sign( float3 v )\n    \{\n        return float3(sign(v.x), sign(v.y), sign(v.z));\n    \}\n\n\n    // \"safe\" div\n    float sdiv( float a, float b )\n    \{\n        if(b == 0.0f)\n        \{\n        return 0.0f;\n        \}\n        else\n        \{\n        return a / b;\n        \}\n    \}\n    \n\n    // convert radians to degrees\n    float degrees( float radians )\n    \{\n      return radians * 180.0f / PI;\n    \}\n\n    float abs( float a )\n    \{\n      return fabs(a);\n    \}\n\n    float3 float3abs( float3 a )\n    \{\n      return fabs(a);\n    \}\n  \n\n  // get the y value of f(x) where the fuction is defined as a line between two points\n  // the two points as passed as an array \[a.x, a.y, b.x, b.y]\n  float lerp1D( float4 table, float x)\n  \{\n    float m = (table.w-table.y) / (table.z-table.x);\n    float c = table.y - (m*table.x);\n    float y = x*m+c;\n    return y;\n  \}\n\n  float3 float3_to_domain_100( float3 v )\n  \{\n    return v;\n  \}\n  \n\n\n  float hue_angle( float a, float b )\n  \{\n    // \"\"\"\n    // Return the *hue* angle :math:`h` in degrees.\n\n    // Parameters\n    // ----------\n    // a\n    //     Opponent colour dimension :math:`a`.\n    // b\n    //     Opponent colour dimension :math:`b`.\n\n    // Returns\n    // -------\n    // :class:`numpy.floating` or :class:`numpy.ndarray`\n    //     *Hue* angle :math:`h` in degrees.\n\n    // Examples\n    // --------\n    // >>> a = -0.000624112068243\n    // >>> b = -0.000506270106773\n    // >>> hue_angle(a, b)  # doctest: +ELLIPSIS\n    // 219.0484326...\n    // \"\"\"\n\n    // a = as_float_array(a);\n    // b = as_float_array(b);\n\n    float h = degrees(atan2(b, a)) / 360;\n\n    return h;\n  \}\n\n  float clip(float x, float a, float b)\n  \{\n    return max(a, min(x, b));\n  \}\n\n  float mod(float a, float N)\n  \{\n    return a - N*floor(a/N);\n  \} \n\n  float radians(float a)\n  \{\n    return a * PI / 180.0f;\n  \}\n\n  float achromatic_response_forward(float3 RGB)\n  \{\n    //   \"\"\"\n    //   Return the achromatic response :math:`A` from given compressed\n    //   *CAM16* transform sharpened *RGB* array and :math:`N_\{bb\}` chromatic\n    //   induction factor for forward *Hellwig and Fairchild (2022)* implementation.\n\n    //   Parameters\n    //   ----------\n    //   RGB\n    //       Compressed *CAM16* transform sharpened *RGB* array.\n\n    //   Returns\n    //   -------\n    //   :class:`numpy.floating` or :class:`numpy.ndarray`\n    //       Achromatic response :math:`A`.\n\n    //   Examples\n    //   --------\n    //   >>> RGB = np.array(\[7.94634384, 7.94713791, 7.9488967])\n    //   >>> achromatic_response_forward(RGB)  # doctest: +ELLIPSIS\n    //   23.9322704...\n    //   \"\"\"\n\n    float R = RGB.x;\n    float G = RGB.y;\n    float B = RGB.z;\n\n\n    float A = 2 * R + G + 0.05 * B - 0.305;\n\n    return A;\n  \}\n\n  float colourfulness_correlate(float N_c,float e_t,float a,float b) \n  \{\n    // \"\"\"\n    // Return the *colourfulness* correlate :math:`M`.\n\n    // Parameters\n    // ----------\n    // N_c\n    //     Surround chromatic induction factor :math:`N_\{c\}`.\n    // e_t\n    //     Eccentricity factor :math:`e_t`.\n    // a\n    //     Opponent colour dimension :math:`a`.\n    // b\n    //     Opponent colour dimension :math:`b`.\n\n    // Returns\n    // -------\n    // :class:`numpy.floating` or :class:`numpy.ndarray`\n    //     *Colourfulness* correlate :math:`M`.\n\n    // Examples\n    // --------\n    // >>> N_c = 1\n    // >>> e_t = 1.13423124867\n    // >>> a = -0.00063418423001\n    // >>> b = -0.000479072513542\n    // >>> colourfulness_correlate(N_c, e_t, a, b)  # doctest: +ELLIPSIS\n    // 0.0387637...\n    // \"\"\"\n\n    // N_c = as_float_array(N_c)\n    // e_t = as_float_array(e_t)\n    // a = as_float_array(a)\n    // b = as_float_array(b)\n\n    float M = 43 * N_c * e_t * sqrt(pow(a,2) + pow(b,2));\n\n    return M;\n  \}\n\n\n\n  float degree_of_adaptation(float  F, float L_A )\n    \{\n    // \"\"\"\n    // Return the degree of adaptation :math:`D` from given surround maximum\n    // degree of adaptation :math:`F` and adapting field *luminance* :math:`L_A`\n    // in :math:`cd/m^2`.\n\n    // Parameters\n    // ----------\n    // F\n    //     Surround maximum degree of adaptation :math:`F`.\n    // L_A\n    //     Adapting field *luminance* :math:`L_A` in :math:`cd/m^2`.\n\n    // Returns\n    // -------\n    // :class:`numpy.floating` or :class:`numpy.ndarray`\n    //     Degree of adaptation :math:`D`.\n\n    // Examples\n    // --------\n    // >>> degree_of_adaptation(1.0, 318.31)  # doctest: +ELLIPSIS\n    // 0.9944687...\n    // \"\"\"\n\n    // F = as_float_array(F)\n    // L_A = as_float_array(L_A)\n\n    float D = F * (1 - (1 / 3.6) * exp((-L_A - 42) / 92));\n\n    return D;\n    \}\n\n\n  float3 XYZ_to_Hellwig2022_JMh( float3 XYZ, float3 XYZ_w, float L_A, float Y_b, float3 surround, bool discount_illuminant)\n    \{\n//     \"\"\"\n//     Compute the *Hellwig and Fairchild (2022)* colour appearance model\n//     correlates from given *CIE XYZ* tristimulus values.\n\n//     Parameters\n//     ----------\n//     XYZ\n//         *CIE XYZ* tristimulus values of test sample / stimulus.\n//     XYZ_w\n//         *CIE XYZ* tristimulus values of reference white.\n//     L_A\n//         Adapting field *luminance* :math:`L_A` in :math:`cd/m^2`, (often taken\n//         to be 20% of the luminance of a white object in the scene).\n//     Y_b\n//         Luminous factor of background :math:`Y_b` such as\n//         :math:`Y_b = 100 x L_b / L_w` where :math:`L_w` is the luminance of the\n//         light source and :math:`L_b` is the luminance of the background. For\n//         viewing images, :math:`Y_b` can be the average :math:`Y` value for the\n//         pixels in the entire image, or frequently, a :math:`Y` value of 20,\n//         approximate an :math:`L^*` of 50 is used.\n//     surround\n//         Surround viewing conditions induction factors.\n//     discount_illuminant\n//         Truth value indicating if the illuminant should be discounted.\n\n//     Returns\n//     -------\n//     :class:`colour.CAM_Specification_Hellwig2022`\n//         *Hellwig and Fairchild (2022)* colour appearance model specification.\n\n//     Notes\n//     -----\n//     +------------+-----------------------+---------------+\n//     | **Domain** | **Scale - Reference** | **Scale - 1** |\n//     +============+=======================+===============+\n//     | ``XYZ``    | \[0, 100]              | \[0, 1]        |\n//     +------------+-----------------------+---------------+\n//     | ``XYZ_w``  | \[0, 100]              | \[0, 1]        |\n//     +------------+-----------------------+---------------+\n\n//     +-------------------------------------+-----------------------+-----------\\\n// ----+\n//     | **Range**                           | **Scale - Reference** | **Scale - \\\n// 1** |\n//     +=====================================+=======================+===========\\\n// ====+\n//     | ``CAM_Specification_Hellwig2022.J`` | \[0, 100]              | \[0, 1]    \\\n//     |\n//     +-------------------------------------+-----------------------+-----------\\\n// ----+\n//     | ``CAM_Specification_Hellwig2022.C`` | \[0, 100]              | \[0, 1]    \\\n//     |\n//     +-------------------------------------+-----------------------+-----------\\\n// ----+\n//     | ``CAM_Specification_Hellwig2022.h`` | \[0, 360]              | \[0, 1]    \\\n//     |\n//     +-------------------------------------+-----------------------+-----------\\\n// ----+\n//     | ``CAM_Specification_Hellwig2022.s`` | \[0, 100]              | \[0, 1]    \\\n//     |\n//     +-------------------------------------+-----------------------+-----------\\\n// ----+\n//     | ``CAM_Specification_Hellwig2022.Q`` | \[0, 100]              | \[0, 1]    \\\n//     |\n//     +-------------------------------------+-----------------------+-----------\\\n// ----+\n//     | ``CAM_Specification_Hellwig2022.M`` | \[0, 100]              | \[0, 1]    \\\n//     |\n//     +-------------------------------------+-----------------------+-----------\\\n// ----+\n//     | ``CAM_Specification_Hellwig2022.H`` | \[0, 400]              | \[0, 1]    \\\n//     |\n//     +-------------------------------------+-----------------------+-----------\\\n// ----+\n\n//     References\n//     ----------\n//     :cite:`Fairchild2022`, :cite:`Hellwig2022`\n\n//     Examples\n//     --------\n//     >>> XYZ = np.array(\[19.01, 20.00, 21.78])\n//     >>> XYZ_w = np.array(\[95.05, 100.00, 108.88])\n//     >>> L_A = 318.31\n//     >>> Y_b = 20.0\n//     >>> surround = VIEWING_CONDITIONS_Hellwig2022\['Average']\n//     >>> XYZ_to_Hellwig2022(XYZ, XYZ_w, L_A, Y_b, surround)\n//     ... # doctest: +ELLIPSIS\n//     CAM_Specification_Hellwig2022(J=41.7312079..., C=0.0257636..., \\\n// h=217.0679597..., s=0.0608550..., Q=55.8523226..., M=0.0339889..., \\\n// H=275.5949861..., HC=None)\n//     \"\"\"\n\n    XYZ = float3_to_domain_100(XYZ);\n    XYZ_w = float3_to_domain_100(XYZ_w);\n    float _X_w = XYZ_w.x ;\n    float Y_w = XYZ_w.y ;\n    float _Z_w = XYZ_w.z ;\n    // L_A = as_float_array(L_A)\n    // Y_b = as_float_array(Y_b)\n\n    // # Step 0\n    // # Converting *CIE XYZ* tristimulus values to sharpened *RGB* values.\n    float3x3 MATRIX_16 = CAT_CAT16;\n    float3 RGB_w = vector_dot(MATRIX_16, XYZ_w);\n\n    // # Computing degree of adaptation :math:`D`.\n    float D = clip(degree_of_adaptation(surround.x, L_A), 0, 1);\n    if(discount_illuminant)\n    \{\n        D = 1.0f;\n    \}\n\n\n    // # Viewing conditions dependent parameters\n    float k = 1 / (5 * L_A + 1);\n    float k4 = pow(k,4);\n    float F_L = 0.2f * k4 * (5.0f * L_A) + 0.1f * pow((1.0f - k4), 2.0f) * spow(5.0f * L_A, 1.0f / 3.0f) ;\n    float n = sdiv(Y_b, Y_w);\n    float z = 1.48 + sqrt(n);\n\n    // // float D_RGB = ( D\[..., np.newaxis] * Y_w\[..., np.newaxis] / RGB_w + 1 - D\[..., np.newaxis] )\n    float3 D_RGB = D * Y_w / RGB_w + 1 - D;\n    float3 RGB_wc = D_RGB * RGB_w;\n    \n    // # Applying forward post-adaptation non-linear response compression.\n    // F_L_RGB = spow(F_L\[..., np.newaxis] * np.absolute(RGB_wc) / 100, 0.42)\n    float3 F_L_RGB = float3spow(F_L * float3abs(RGB_wc) / 100.0f, 0.42f);\n\n    // # Computing achromatic responses for the whitepoint.\n    // RGB_aw = (400 * np.sign(RGB_wc) * F_L_RGB) / (27.13 + F_L_RGB) + 0.1\n    float3 RGB_aw = (400.0f * float3sign(RGB_wc) * F_L_RGB) / (27.13f + F_L_RGB) + 0.1f;\n\n    // # Computing achromatic responses for the whitepoint.\n    // R_aw, G_aw, B_aw = tsplit(RGB_aw)\n    float R_aw = RGB_aw.x ;\n    float G_aw = RGB_aw.y ;\n    float B_aw = RGB_aw.z ;\n    // A_w = 2 * R_aw + G_aw + 0.05 * B_aw - 0.305\n    float A_w = 2 * R_aw + G_aw + 0.05f * B_aw - 0.305f;\n\n    // # Step 1\n    // # Converting *CIE XYZ* tristimulus values to sharpened *RGB* values.\n    // RGB = vector_dot(MATRIX_16, XYZ)\n    float3 RGB = vector_dot(MATRIX_16, XYZ);\n\n    // # Step 2\n    // RGB_c = D_RGB * RGB\n    float3 RGB_c = D_RGB * RGB;\n\n    // # Step 3\n    // # Applying forward post-adaptation non-linear response compression.\n    // F_L_RGB = spow(F_L\[..., np.newaxis] * np.absolute(RGB_c) / 100, 0.42)\n    float3 F_L_RGB_2 = float3spow(F_L * float3abs(RGB_c) / 100.0f, 0.42f);\n    // RGB_a = (400 * np.sign(RGB_c) * F_L_RGB) / (27.13 + F_L_RGB) + 0.1\n    float3 RGB_a = (400.0f * float3sign(RGB_c) * F_L_RGB_2) / (27.13f + F_L_RGB_2) + 0.1f;\n\n\n    // # Step 4\n    // # Converting to preliminary cartesian coordinates.\n    // R_a, G_a, B_a = tsplit(RGB_a)\n    float R_a = RGB_a.x ;\n    float G_a = RGB_a.y ;\n    float B_a = RGB_a.z ;\n    // a = R_a - 12 * G_a / 11 + B_a / 11\n    float a = R_a - 12.0f * G_a / 11.0f + B_a / 11.0f;\n    // b = (R_a + G_a - 2 * B_a) / 9\n    float b = (R_a + G_a - 2.0f * B_a) / 9.0f;\n\n    // # Computing the *hue* angle :math:`h`.\n    // h = np.degrees(np.arctan2(b, a)) % 360\n    // Unclear why this isnt matching the python version.\n    float h = mod(degrees(atan2(b, a)), 360.0f);\n\n    \n\n    // # Step 5\n    // # Computing eccentricity factor *e_t*.\n    // hr = np.radians(h)\n    float hr = radians(h);\n\n    // _h = hr\n    // _2_h = 2 * hr\n    // _3_h = 3 * hr\n    // _4_h = 4 * hr\n    float _h = hr;\n    float _2_h = 2 * hr;\n    float _3_h = 3 * hr;\n    float _4_h = 4 * hr;\n\n    // e_t = (\n    //     -0.0582 * np.cos(_h)\n    //     - 0.0258 * np.cos(_2_h)\n    //     - 0.1347 * np.cos(_3_h)\n    //     + 0.0289 * np.cos(_4_h)\n    //     - 0.1475 * np.sin(_h)\n    //     - 0.0308 * np.sin(_2_h)\n    //     + 0.0385 * np.sin(_3_h)\n    //     + 0.0096 * np.sin(_4_h)\n    //     + 1\n    // )\n    float e_t = (\n        -0.0582f * cos(_h)\n        - 0.0258f * cos(_2_h)\n        - 0.1347f * cos(_3_h)\n        + 0.0289f * cos(_4_h)\n        - 0.1475f * sin(_h)\n        - 0.0308f * sin(_2_h)\n        + 0.0385f * sin(_3_h)\n        + 0.0096f * sin(_4_h)\n        + 1.0f\n    );\n\n    // # Step 6\n    // # Computing achromatic responses for the stimulus.\n    // R_a, G_a, B_a = tsplit(RGB_a)\n    float R_a2 = RGB_a.x ;\n    float G_a2 = RGB_a.y ;\n    float B_a2 = RGB_a.z ;\n    // A = 2 * R_a + G_a + 0.05 * B_a - 0.305\n    float A = 2 * R_a2 + G_a2 + 0.05f * B_a2 - 0.305f;\n\n    // # Step 7\n    // # Computing the correlate of *Lightness* :math:`J`.\n    // with sdiv_mode():\n    //     J = 100 * spow(sdiv(A, A_w), surround.c * z)\n\n    float J = 100.0f * spow(sdiv(A, A_w), surround.y * z);\n\n    // # Step 8\n    // # Computing the correlate of *brightness* :math:`Q`.\n    // with sdiv_mode():\n    //     Q = (2 / as_float(surround.c)) * (J / 100) * A_w\n    float Q = (2.0f / float(surround.y)) * (J / 100.0f) * A_w;\n\n    // # Step 9\n    // # Computing the correlate of *colourfulness* :math:`M`.\n    // M = 43 * surround.N_c * e_t * np.sqrt(a**2 + b**2)\n    float M = 43.0f * surround.z * e_t * sqrt(a * a + b * b);\n\n    // # Computing the correlate of *chroma* :math:`C`.\n    // with sdiv_mode():\n    //     C = 35 * sdiv(M, A_w)\n    float C = 35.0f * sdiv(M, A_w);\n\n\n    // # Computing the correlate of *saturation* :math:`s`.\n    // with sdiv_mode():\n    //     s = 100 * sdiv(M, Q)\n    float s = 100.0f * sdiv(M, Q);\n\n\n\n    // return XYZ_w;\n    // return RGB_w;\n    // return \{D,k,k4\};\n    // return \{F_L,n,z\};\n    // return RGB_a;\n    return \{J,M,h\};\n    // return XYZ;\n    \}\n\n    float3 Hellwig2022_JMh_to_XYZ( float3 JMh, float3 XYZ_w, float L_A, float Y_b, float3 surround, bool discount_illuminant)\n    \{\n        float J = JMh.x;\n        float M = JMh.y;\n        float h = JMh.z;\n\n        // L_A = as_float_array(L_A)\n        // XYZ_w = to_domain_100(XYZ_w)\n        // _X_w, Y_w, _Z_w = tsplit(XYZ_w)\n        float _X_w = XYZ_w.x;\n        float Y_w = XYZ_w.y;\n        float _Z_w = XYZ_w.z;\n\n        // # Step 0\n        // # Converting *CIE XYZ* tristimulus values to sharpened *RGB* values.\n        // RGB_w = vector_dot(MATRIX_16, XYZ_w)\n        float3x3 MATRIX_16 = CAT_CAT16;\n        float3 RGB_w = vector_dot(MATRIX_16, XYZ_w);\n\n\n        // # Computing degree of adaptation :math:`D`.\n        float D = clip(degree_of_adaptation(surround.x, L_A), 0, 1);\n        if(discount_illuminant)\n        \{\n            D = 1.0f;\n        \}\n\n\n\n        // # Viewing conditions dependent parameters\n        float k = 1 / (5 * L_A + 1);\n        float k4 = pow(k,4);\n        float F_L = 0.2f * k4 * (5.0f * L_A) + 0.1f * pow((1.0f - k4), 2.0f) * spow(5.0f * L_A, 1.0f / 3.0f) ;\n        float n = sdiv(Y_b, Y_w);\n        float z = 1.48 + sqrt(n);\n\n        // // float D_RGB = ( D\[..., np.newaxis] * Y_w\[..., np.newaxis] / RGB_w + 1 - D\[..., np.newaxis] )\n        float3 D_RGB = D * Y_w / RGB_w + 1 - D;\n        float3 RGB_wc = D_RGB * RGB_w;\n        \n        // # Applying forward post-adaptation non-linear response compression.\n        // F_L_RGB = spow(F_L\[..., np.newaxis] * np.absolute(RGB_wc) / 100, 0.42)\n        float3 F_L_RGB = float3spow(F_L * float3abs(RGB_wc) / 100.0f, 0.42f);\n\n        // # Computing achromatic responses for the whitepoint.\n        // RGB_aw = (400 * np.sign(RGB_wc) * F_L_RGB) / (27.13 + F_L_RGB) + 0.1\n        float3 RGB_aw = (400.0f * float3sign(RGB_wc) * F_L_RGB) / (27.13f + F_L_RGB) + 0.1f;\n\n        // # Computing achromatic responses for the whitepoint.\n        // R_aw, G_aw, B_aw = tsplit(RGB_aw)\n        float R_aw = RGB_aw.x ;\n        float G_aw = RGB_aw.y ;\n        float B_aw = RGB_aw.z ;\n        // A_w = 2 * R_aw + G_aw + 0.05 * B_aw - 0.305\n        float A_w = 2 * R_aw + G_aw + 0.05f * B_aw - 0.305f;\n\n        // # Step 2\n        // # Computing eccentricity factor *e_t*.\n        // hr = np.radians(h)\n        float hr = radians(h);\n\n\n        // _h = hr\n        // _2_h = 2 * hr\n        // _3_h = 3 * hr\n        // _4_h = 4 * hr\n        float _h = hr;\n        float _2_h = 2 * hr;\n        float _3_h = 3 * hr;\n        float _4_h = 4 * hr;\n    \n        // e_t = (\n        //     -0.0582 * np.cos(_h)\n        //     - 0.0258 * np.cos(_2_h)\n        //     - 0.1347 * np.cos(_3_h)\n        //     + 0.0289 * np.cos(_4_h)\n        //     - 0.1475 * np.sin(_h)\n        //     - 0.0308 * np.sin(_2_h)\n        //     + 0.0385 * np.sin(_3_h)\n        //     + 0.0096 * np.sin(_4_h)\n        //     + 1\n        // )\n        float e_t = (\n            -0.0582f * cos(_h)\n            - 0.0258f * cos(_2_h)\n            - 0.1347f * cos(_3_h)\n            + 0.0289f * cos(_4_h)\n            - 0.1475f * sin(_h)\n            - 0.0308f * sin(_2_h)\n            + 0.0385f * sin(_3_h)\n            + 0.0096f * sin(_4_h)\n            + 1.0f\n        );\n\n        // # Computing achromatic response :math:`A` for the stimulus.\n        // A = A = A_w * spow(J / 100, 1 / (surround.c * z))\n        float A = A_w * spow(J / 100.0f, 1.0f / (surround.y * z));\n\n        // # Computing *P_p_1* to *P_p_2*.\n        // P_p_1 = 43 * surround.N_c * e_t\n        // P_p_2 = A\n        float P_p_1 = 43.0f * surround.z * e_t;\n        float P_p_2 = A;\n\n\n        // # Step 3\n        // # Computing opponent colour dimensions :math:`a` and :math:`b`.\n        // with sdiv_mode():\n        //     gamma = M / P_p_1\n        float gamma = M / P_p_1;\n    \n        // a = gamma * np.cos(hr)\n        float a = gamma * cos(hr);\n        // b = gamma * np.sin(hr)\n        float b = gamma * sin(hr);\n\n\n        // # Step 4\n        // # Applying post-adaptation non-linear response compression matrix.\n        // RGB_a = (\n        //     vector_dot(\n        //         \[\n        //             \[460, 451, 288],\n        //             \[460, -891, -261],\n        //             \[460, -220, -6300],\n        //         ],\n        //         tstack(\[P_p_2, a, b]),\n        //     )\n        //     / 1403\n        // )\n\n        float panlrcm_data\[]=\n        \{\n            460.0f, 451.0f, 288.0f,\n            460.0f, -891.0f, -261.0f,\n            460.0f, -220.0f, -6300.0f,\n        \};\n        float3x3 panlrcm;\n        panlrcm.setArray(panlrcm_data);\n\n        float3 RGB_a = vector_dot(panlrcm, float3(P_p_2, a, b)) / 1403.0f;\n\n        // # Step 5\n        // # Applying inverse post-adaptation non-linear response compression.\n        // RGB_c = (\n        //     np.sign(RGB_a)\n        //     * 100\n        //     / F_L\[..., np.newaxis]\n        //     * spow(\n        //         (27.13 * np.absolute(RGB_a)) / (400 - np.absolute(RGB_a)),\n        //         1 / 0.42,\n        //     )\n        // )\n        float3 RGB_c = float3sign(RGB_a) * 100.0f / F_L * float3spow((27.13f * float3abs(RGB_a)) / (400.0f - float3abs(RGB_a)), 1.0f / 0.42f);\n\n        // # Step 6\n        // RGB = RGB_c / D_RGB\n        float3 RGB = RGB_c / D_RGB;\n    \n        // # Step 7\n        // XYZ = vector_dot(MATRIX_INVERSE_16, RGB)\n        float3x3 MATRIX_INVERSE_16 = CAT_CAT16.invert();\n        float3 XYZ = vector_dot(MATRIX_INVERSE_16, RGB);\n\n        return XYZ;\n\n    \}\n\n\n  void init()\n  \{\n    HALF_MIN = 0.0000000596046448f;\n    HALF_MAX = 65504.0f;\n\n    float CAT_CAT16_data\[]=\n    \{\n      0.401288, 0.650173, -0.051461,\n      -0.250268, 1.204414, 0.045854,\n      -0.002079, 0.048952, 0.953127,\n    \};\n\n    CAT_CAT16.setArray(CAT_CAT16_data);\n\n  \}\n\n\n  void process()\n  \{\n    SampleType(src) source = src();\n    float3 srcRGB(source.x, source.y, source.z);\n    float3 dstRGB;\n    float3 diagnostic;\n\n    // diagnostic =  srcRGB;\n\n    // float3 surround(1.0f, 0.69f, 1.0f);\n    // float3 XYZ_w(95.05f, 100.00f, 108.88f);\n\n    if (direction == 0)\n    \{\n        float3 JMh = XYZ_to_Hellwig2022_JMh(srcRGB, XYZ_w, L_A, Y_b,surround,discount_illuminant);\n        dstRGB = JMh;\n    \}\n    else\n    \{\n        float3 XYZ_out = Hellwig2022_JMh_to_XYZ(srcRGB, XYZ_w, L_A, Y_b, surround, discount_illuminant);\n        dstRGB = XYZ_out;\n    \}\n\n    diagnostic = dstRGB;\n\n\n    dst() = float4(diagnostic.x, diagnostic.y, diagnostic.z, source.w ); \n  \}\n\};\n"
 rebuild ""
 hellwig2022_XYZ_w {95.05 100 108.88}
 hellwig2022_L_A 318.31
 hellwig2022_Y_b 20
 hellwig2022_surround {1 0.69 1}
 rebuild_finalise ""
 name BlinkScript1
 xpos 427
 ypos 8
}
Constant {
 inputs 0
 channels rgb
 color {19.01 20 21.78 0}
 format "256 256 0 0 256 256 1 square_256"
 name Constant1
 label "check values as used by Thomas's code"
 xpos 713
 ypos -89
}
