
kernel hellwig2022 : ImageComputationKernel<ePixelWise>
{
  Image<eRead, eAccessPoint, eEdgeClamped> src; // the input image
  Image<eWrite> dst; // the output image

  param:

    // the kernel parameters
    int direction; // the direction of the convolution
    int catDataSelection; // original vs modified CAT16 matrix

    float3 XYZ_w;
    float L_A;
    float Y_b;
    float3 L_B;
    float3 surround;
    bool discount_illuminant;
    bool HK_mode;

    // xy coordintes for custom CAT matrix
    float2 rxy;
    float2 gxy;
    float2 bxy;
    float2 wxy;


  local:
    float HALF_MIN;
    float HALF_MAX;

    float3x3 CAT_CAT16;


  void define()
  {

  }

  // multiplies a 3D vector with a 3x3 matrix
  float3 vector_dot( float3x3 m, float3 v)
  {
    float3 r = 1.0f;
    for(int c = 0; c<3; c++)
    {
      r[c] = m[c][0]*v.x + m[c][1]*v.y + m[c][2]*v.z;
    }

    return r;
  }

  // linear interpolation between two values a & b with the bias t
  float lerp(float a, float b, float t)
  {
    return a + t * (b - a);
  }

        // "safe" power function to avoid NANs or INFs when taking a fractional power of a negative base
    // this one initially returned -pow(abs(b), e) for negative b
    // but this ended up producing undesirable results in some cases
    // so now it just returns 0.0 instead
    float spow( float base, float exponent )
    {
        if(base < 0.0f && exponent != floor(exponent) )
        {
        return 0.0f;
        }
        else
        {
        return pow(base, exponent); 
        }
    }

    float3 float3spow( float3 base, float exponent )
    {
        return float3(spow(base.x, exponent), spow(base.y, exponent), spow(base.z, exponent));
    }

    float3 float3sign( float3 v )
    {
        return float3(sign(v.x), sign(v.y), sign(v.z));
    }


    // "safe" div
    float sdiv( float a, float b )
    {
        if(b == 0.0f)
        {
        return 0.0f;
        }
        else
        {
        return a / b;
        }
    }
    

    // convert radians to degrees
    float degrees( float radians )
    {
      return radians * 180.0f / PI;
    }

    float abs( float a )
    {
      return fabs(a);
    }

    float3 float3abs( float3 a )
    {
      return fabs(a);
    }
  

  // get the y value of f(x) where the fuction is defined as a line between two points
  // the two points as passed as an array [a.x, a.y, b.x, b.y]
  float lerp1D( float4 table, float x)
  {
    float m = (table.w-table.y) / (table.z-table.x);
    float c = table.y - (m*table.x);
    float y = x*m+c;
    return y;
  }

  float3 float3_to_domain_100( float3 v )
  {
    return v;
  }
  


  float hue_angle( float a, float b )
  {
    // """
    // Return the *hue* angle :math:`h` in degrees.

    // Parameters
    // ----------
    // a
    //     Opponent colour dimension :math:`a`.
    // b
    //     Opponent colour dimension :math:`b`.

    // Returns
    // -------
    // :class:`numpy.floating` or :class:`numpy.ndarray`
    //     *Hue* angle :math:`h` in degrees.

    // Examples
    // --------
    // >>> a = -0.000624112068243
    // >>> b = -0.000506270106773
    // >>> hue_angle(a, b)  # doctest: +ELLIPSIS
    // 219.0484326...
    // """

    // a = as_float_array(a);
    // b = as_float_array(b);

    float h = degrees(atan2(b, a)) / 360;

    return h;
  }

  float clip(float x, float a, float b)
  {
    return max(a, min(x, b));
  }

  float mod(float a, float N)
  {
    return a - N*floor(a/N);
  } 

  float radians(float a)
  {
    return a * PI / 180.0f;
  }




  float hue_angle_dependency_Hellwig2022(float h)
  {
    // """
    // Compute the hue angle dependency of the *Helmholtzâ€“Kohlrausch* effect.
    // Parameters
    // ----------
    // h
    //     Hue :math:`h` angle in degrees.
    // Returns
    // -------
    // :class:`numpy.floating` or :class:`numpy.ndarray`
    //     Hue angle dependency.
    // Examples
    // --------
    // >>> hue_angle_dependency_Hellwig2022(219.0484326582719)
    // ... # doctest: +ELLIPSIS
    // 0.8962565...
    // """

    // h = as_float_array(h)
    return float(         \
     -0.160 * cos(h)      \
    + 0.132 * cos(2 * h)  \
    - 0.405 * sin(h)      \
    + 0.080 * sin(2 * h)  \ 
    + 0.792               \
    );

    // return float( -0.160f * cos(h) + 0.132f * cos(2.0f * h)  - 0.405f * sin(h)  + 0.080f * sin(2.0f * h) + 0.792f );
    }


  float3x3  RGBPrimsToXYZMatrix(float2 rxy, float2 gxy, float2 bxy, float2 wxy,float Y, bool direction)
  {
    // # given r g b chromaticities and whitepoint, convert RGB colors to XYZ
    // # based on CtlColorSpace.cpp from the CTL source code : 77
    // # param: xy - dict of chromaticity xy coordinates: rxy: float2(x, y) etc
    // # param: Y - luminance of "white" - defaults to 1.0
    // # param: inverse - calculate XYZ to RGB instead

    float2 r = rxy;
    float2 g = gxy;
    float2 b = bxy;
    float2 w = wxy;

    float X = w.x * Y / w.y;
    float Z = (1 - w.x - w.y) * Y / w.y;

    // # Scale factors for matrix rows
    float d = r.x * (b.y - g.y) + b.x * (g.y - r.y) + g.x * (r.y - b.y);

    float Sr =    (X * (b.y - g.y) -      \
            g.x * (Y * (b.y - 1.0f) +  \
            b.y  * (X + Z)) +       \
            b.x  * (Y * (g.y - 1.0f) + \
            g.y * (X + Z))) / d ;
    
    float Sg =    (X * (r.y - b.y) +      \
            r.x * (Y * (b.y - 1.0f) +  \
            b.y * (X + Z)) -        \
            b.x * (Y * (r.y - 1.0f) +  \
            r.y * (X + Z))) / d ;

    float Sb =    (X * (g.y - r.y) -      \
            r.x * (Y * (g.y - 1.0f) +  \
            g.y * (X + Z)) +        \
            g.x * (Y * (r.y - 1.0f) +  \
            r.y * (X + Z))) / d ;

    // # Assemble the matrix
    float Mdata[] =
    {
            Sr * r.x, Sr * r.y, Sr * (1.0f - r.x - r.y),
            Sg * g.x, Sg * g.y, Sg * (1.0f - g.x - g.y),
            Sb * b.x, Sb * b.y, Sb * (1.0f - b.x - b.y),
    };

    float MdataNukeOrder[] = {
      Mdata[0], Mdata[3], Mdata[6],
      Mdata[1], Mdata[4], Mdata[7],
      Mdata[2], Mdata[5], Mdata[8],
    };

    float3x3 newMatrix;
    newMatrix.setArray(MdataNukeOrder);

    // create inverse matrix
    float3x3 newMatrixInverse = newMatrix.invert();

    // return forward or inverse matrix
    if (direction == 0)
    {
      return newMatrix;
    }
    else if (direction == 1)
    {
      return newMatrixInverse;
    }
  }


  float achromatic_response_forward(float3 RGB)
  {
    //   """
    //   Return the achromatic response :math:`A` from given compressed
    //   *CAM16* transform sharpened *RGB* array and :math:`N_{bb}` chromatic
    //   induction factor for forward *Hellwig and Fairchild (2022)* implementation.

    //   Parameters
    //   ----------
    //   RGB
    //       Compressed *CAM16* transform sharpened *RGB* array.

    //   Returns
    //   -------
    //   :class:`numpy.floating` or :class:`numpy.ndarray`
    //       Achromatic response :math:`A`.

    //   Examples
    //   --------
    //   >>> RGB = np.array([7.94634384, 7.94713791, 7.9488967])
    //   >>> achromatic_response_forward(RGB)  # doctest: +ELLIPSIS
    //   23.9322704...
    //   """

    float R = RGB.x;
    float G = RGB.y;
    float B = RGB.z;


    float A = 2 * R + G + 0.05 * B - 0.305;

    return A;
  }

  float colourfulness_correlate(float N_c,float e_t,float a,float b) 
  {
    // """
    // Return the *colourfulness* correlate :math:`M`.

    // Parameters
    // ----------
    // N_c
    //     Surround chromatic induction factor :math:`N_{c}`.
    // e_t
    //     Eccentricity factor :math:`e_t`.
    // a
    //     Opponent colour dimension :math:`a`.
    // b
    //     Opponent colour dimension :math:`b`.

    // Returns
    // -------
    // :class:`numpy.floating` or :class:`numpy.ndarray`
    //     *Colourfulness* correlate :math:`M`.

    // Examples
    // --------
    // >>> N_c = 1
    // >>> e_t = 1.13423124867
    // >>> a = -0.00063418423001
    // >>> b = -0.000479072513542
    // >>> colourfulness_correlate(N_c, e_t, a, b)  # doctest: +ELLIPSIS
    // 0.0387637...
    // """

    // N_c = as_float_array(N_c)
    // e_t = as_float_array(e_t)
    // a = as_float_array(a)
    // b = as_float_array(b)

    float M = 43 * N_c * e_t * sqrt(pow(a,2) + pow(b,2));

    return M;
  }



  float degree_of_adaptation(float  F, float L_A )
    {
    // """
    // Return the degree of adaptation :math:`D` from given surround maximum
    // degree of adaptation :math:`F` and adapting field *luminance* :math:`L_A`
    // in :math:`cd/m^2`.

    // Parameters
    // ----------
    // F
    //     Surround maximum degree of adaptation :math:`F`.
    // L_A
    //     Adapting field *luminance* :math:`L_A` in :math:`cd/m^2`.

    // Returns
    // -------
    // :class:`numpy.floating` or :class:`numpy.ndarray`
    //     Degree of adaptation :math:`D`.

    // Examples
    // --------
    // >>> degree_of_adaptation(1.0, 318.31)  # doctest: +ELLIPSIS
    // 0.9944687...
    // """

    // F = as_float_array(F)
    // L_A = as_float_array(L_A)

    float D = F * (1 - (1 / 3.6) * exp((-L_A - 42) / 92));

    return D;
    }



    // def d_post_adaptation_non_linear_response_compression_forward(
    //     RGB: ArrayLike, F_L: FloatingOrArrayLike
    // ) -> NDArray:
    //     F_L_RGB = spow(F_L[..., np.newaxis] * RGB / 100, 0.42)
    //     F_L_100 = spow(F_L[..., np.newaxis] / 100, 0.42)
    
    //     d_RGB_a = (
    //         400
    //         * ((0.42 * 27.13) * spow(RGB, -0.58) * F_L_100)
    //         / (F_L_RGB + 27.13) ** 2
    //     )
    
    //     return d_RGB_a

    // ** example
        // (a**2 + b**2)
        // (a * a + b * b);
    



        
    // def post_adaptation_non_linear_response_compression_forward(
    //     RGB: ArrayLike, F_L: FloatingOrArrayLike
    // ) -> NDArray:


    //     RGB = as_float_array(RGB)
    //     F_L = as_float_array(F_L)

    //     F_L_RGB = spow(F_L[..., np.newaxis] * np.absolute(RGB) / 100, 0.42)
    //     RGB_c = (400 * np.sign(RGB) * F_L_RGB) / (27.13 + F_L_RGB) + 0.1

    //     return RGB_c


    float3 post_adaptation_non_linear_response_compression_forward(float3 RGB, float F_L)
    {
        // RGB = as_float_array(RGB)
        // F_L = as_float_array(F_L)
    
        float3 F_L_RGB = float3spow(F_L * float3abs(RGB) / 100.0f, 0.42f);
        float3 RGB_c = (400.0f * sign(RGB) * F_L_RGB) / (27.13f + F_L_RGB) + 0.1f;
    
        return RGB_c;
    }

    
    float3 post_adaptation_non_linear_response_compression_inverse(float3 RGB,float F_L)
    {
        // RGB = as_float_array(RGB)
        // F_L = as_float_array(F_L)


        // RGB_p = (
        //     np.sign(RGB - 0.1)
        //     * 100
        //     / F_L[..., np.newaxis]
        //     * spow(
        //         (27.13 * np.absolute(RGB - 0.1)) / (400 - np.absolute(RGB - 0.1)),
        //         1 / 0.42,
        //     )
        // )


        // RGB_p = ( np.sign(RGB - 0.1) * 100 / F_L[..., np.newaxis] * spow( (27.13 * np.absolute(RGB - 0.1)) / (400 - np.absolute(RGB - 0.1)), 1 / 0.42, ))

        // older compression formula subbed in
        // float3 RGB_p =   float3sign(RGB) * 100.0f / F_L        * float3spow((27.13f * float3abs(RGB)) / (400.0f - float3abs(RGB)), 1.0f / 0.42f);

        // float3 RGB_p =  sign(RGB - 0.1f) * 100.0f / F_L * spow((27.13f * float3abs(RGB - 0.1f)) / (400.0f - float3abs(RGB - 0.1f)), 1.0f / 0.42f);
        float3 RGB_p =  (float3sign(RGB - 0.1f) * 100.0f / F_L * float3spow((27.13f * float3abs(RGB - 0.1f)) / (400.0f - float3abs(RGB - 0.1f)), 1.0f / 0.42f) );
        // float3 RGB_p =   float3sign(RGB) * 100.0f / F_L        * float3spow((27.13f * float3abs(RGB)) / (400.0f - float3abs(RGB)), 1.0f / 0.42f);
        return RGB_p;
    }


    // def d_post_adaptation_non_linear_response_compression_forward(
    //     RGB: ArrayLike, F_L: FloatingOrArrayLike
    // ) -> NDArray:
    //     F_L_RGB = spow(F_L[..., np.newaxis] * RGB / 100, 0.42)
    //     F_L_100 = spow(F_L[..., np.newaxis] / 100, 0.42)
    
    //     d_RGB_a = (  400 * ((0.42 * 27.13) * spow(RGB, -0.58) * F_L_100) / (F_L_RGB + 27.13) ** 2  )
    
    //     return d_RGB_a
    
    
    float3 d_post_adaptation_non_linear_response_compression_forward( float3 RGB, float F_L)
    {
        float3 F_L_RGB = float3spow(F_L * RGB / 100.0f, 0.42f);
        float F_L_100 = spow(F_L / 100.0f, 0.42f);
    
        // float3 d_RGB_a = ( 400.0f * ((0.42f * 27.13f) * float3spow(RGB, -0.58f) * F_L_100)/ (F_L_RGB + 27.13f) ** 2.0f );
           float3 d_RGB_a = ( 400.0f * ((0.42f * 27.13f) * float3spow(RGB, -0.58f) * F_L_100)/ ( (F_L_RGB + 27.13f) *  (F_L_RGB + 27.13f) ));
        //    d_RGB_a = d_RGB_a * d_RGB_a;

        return d_RGB_a;
    }


  float3 XYZ_to_Hellwig2022_linearExtension_JMh( float3 XYZ, float3 XYZ_w, float L_A, float Y_b, float3 surround, bool discount_illuminant)
    {
    //     """
    //     Compute the *Hellwig and Fairchild (2022)* colour appearance model
    //     correlates from given *CIE XYZ* tristimulus values.

    //     Parameters
    //     ----------
    //     XYZ
    //         *CIE XYZ* tristimulus values of test sample / stimulus.
    //     XYZ_w
    //         *CIE XYZ* tristimulus values of reference white.
    //     L_A
    //         Adapting field *luminance* :math:`L_A` in :math:`cd/m^2`, (often taken
    //         to be 20% of the luminance of a white object in the scene).
    //     Y_b
    //         Luminous factor of background :math:`Y_b` such as
    //         :math:`Y_b = 100 x L_b / L_w` where :math:`L_w` is the luminance of the
    //         light source and :math:`L_b` is the luminance of the background. For
    //         viewing images, :math:`Y_b` can be the average :math:`Y` value for the
    //         pixels in the entire image, or frequently, a :math:`Y` value of 20,
    //         approximate an :math:`L^*` of 50 is used.
    //     surround
    //         Surround viewing conditions induction factors.
    //     discount_illuminant
    //         Truth value indicating if the illuminant should be discounted.

    //     Returns
    //     -------
    //     :class:`colour.CAM_Specification_Hellwig2022`
    //         *Hellwig and Fairchild (2022)* colour appearance model specification.

    //     Notes
    //     -----
    //     +------------+-----------------------+---------------+
    //     | **Domain** | **Scale - Reference** | **Scale - 1** |
    //     +============+=======================+===============+
    //     | ``XYZ``    | [0, 100]              | [0, 1]        |
    //     +------------+-----------------------+---------------+
    //     | ``XYZ_w``  | [0, 100]              | [0, 1]        |
    //     +------------+-----------------------+---------------+

    //     +-------------------------------------+-----------------------+-----------\
    // ----+
    //     | **Range**                           | **Scale - Reference** | **Scale - \
    // 1** |
    //     +=====================================+=======================+===========\
    // ====+
    //     | ``CAM_Specification_Hellwig2022.J`` | [0, 100]              | [0, 1]    \
    //     |
    //     +-------------------------------------+-----------------------+-----------\
    // ----+
    //     | ``CAM_Specification_Hellwig2022.C`` | [0, 100]              | [0, 1]    \
    //     |
    //     +-------------------------------------+-----------------------+-----------\
    // ----+
    //     | ``CAM_Specification_Hellwig2022.h`` | [0, 360]              | [0, 1]    \
    //     |
    //     +-------------------------------------+-----------------------+-----------\
    // ----+
    //     | ``CAM_Specification_Hellwig2022.s`` | [0, 100]              | [0, 1]    \
    //     |
    //     +-------------------------------------+-----------------------+-----------\
    // ----+
    //     | ``CAM_Specification_Hellwig2022.Q`` | [0, 100]              | [0, 1]    \
    //     |
    //     +-------------------------------------+-----------------------+-----------\
    // ----+
    //     | ``CAM_Specification_Hellwig2022.M`` | [0, 100]              | [0, 1]    \
    //     |
    //     +-------------------------------------+-----------------------+-----------\
    // ----+
    //     | ``CAM_Specification_Hellwig2022.H`` | [0, 400]              | [0, 1]    \
    //     |
    //     +-------------------------------------+-----------------------+-----------\
    // ----+

    //     References
    //     ----------
    //     :cite:`Fairchild2022`, :cite:`Hellwig2022`

    //     Examples
    //     --------
    //     >>> XYZ = np.array([19.01, 20.00, 21.78])
    //     >>> XYZ_w = np.array([95.05, 100.00, 108.88])
    //     >>> L_A = 318.31
    //     >>> Y_b = 20.0
    //     >>> surround = VIEWING_CONDITIONS_Hellwig2022['Average']
    //     >>> XYZ_to_Hellwig2022(XYZ, XYZ_w, L_A, Y_b, surround)
    //     ... # doctest: +ELLIPSIS
    //     CAM_Specification_Hellwig2022(J=41.7312079..., C=0.0257636..., \
    // h=217.0679597..., s=0.0608550..., Q=55.8523226..., M=0.0339889..., \
    // H=275.5949861..., HC=None)
    //     """

        XYZ = float3_to_domain_100(XYZ);
        XYZ_w = float3_to_domain_100(XYZ_w);
        float _X_w = XYZ_w.x ;
        float Y_w = XYZ_w.y ;
        float _Z_w = XYZ_w.z ;
        // L_A = as_float_array(L_A)
        // Y_b = as_float_array(Y_b)

        // # Step 0
        // # Converting *CIE XYZ* tristimulus values to sharpened *RGB* values.
        float3x3 MATRIX_16 = CAT_CAT16;
        float3 RGB_w = vector_dot(MATRIX_16, XYZ_w);

        // # Computing degree of adaptation :math:`D`.
        float D = clip(degree_of_adaptation(surround.x, L_A), 0, 1);
        if(discount_illuminant)
        {
            D = 1.0f;
        }


        // # Viewing conditions dependent parameters
        float k = 1 / (5 * L_A + 1);
        float k4 = pow(k,4);
        float F_L = 0.2f * k4 * (5.0f * L_A) + 0.1f * pow((1.0f - k4), 2.0f) * spow(5.0f * L_A, 1.0f / 3.0f) ;
        float n = sdiv(Y_b, Y_w);
        float z = 1.48 + sqrt(n);

        // // float D_RGB = ( D[..., np.newaxis] * Y_w[..., np.newaxis] / RGB_w + 1 - D[..., np.newaxis] )
        float3 D_RGB = D * Y_w / RGB_w + 1 - D;
        float3 RGB_wc = D_RGB * RGB_w;
        
        // # Applying forward post-adaptation non-linear response compression.
        // F_L_RGB = spow(F_L[..., np.newaxis] * np.absolute(RGB_wc) / 100, 0.42)
        float3 F_L_RGB = float3spow(F_L * float3abs(RGB_wc) / 100.0f, 0.42f);

        // # Computing achromatic responses for the whitepoint.
        // RGB_aw = (400 * np.sign(RGB_wc) * F_L_RGB) / (27.13 + F_L_RGB) + 0.1
        float3 RGB_aw = (400.0f * float3sign(RGB_wc) * F_L_RGB) / (27.13f + F_L_RGB) + 0.1f;
        

        // # Computing achromatic responses for the whitepoint.
        // R_aw, G_aw, B_aw = tsplit(RGB_aw)
        float R_aw = RGB_aw.x ;
        float G_aw = RGB_aw.y ;
        float B_aw = RGB_aw.z ;
        // A_w = 2 * R_aw + G_aw + 0.05 * B_aw - 0.305
        float A_w = 2 * R_aw + G_aw + 0.05f * B_aw - 0.305f;

        // # Step 1
        // # Converting *CIE XYZ* tristimulus values to sharpened *RGB* values.
        // RGB = vector_dot(MATRIX_16, XYZ)

        float3 RGB = vector_dot(MATRIX_16, XYZ);
        // float3 RGB = XYZ;

        // # Step 2
        // RGB_c = D_RGB * RGB
        float3 RGB_c = D_RGB * RGB;

        // # Step 3
        // # Applying forward post-adaptation non-linear response compression.
        // // F_L_RGB = spow(F_L[..., np.newaxis] * np.absolute(RGB_c) / 100, 0.42)
        // float3 F_L_RGB_2 = float3spow(F_L * float3abs(RGB_c) / 100.0f, 0.42f);
        // // RGB_a = (400 * np.sign(RGB_c) * F_L_RGB) / (27.13 + F_L_RGB) + 0.1
        // float3 RGB_a = (400.0f * float3sign(RGB_c) * F_L_RGB_2) / (27.13f + F_L_RGB_2) + 0.1f;


        // # Step 3
        // # Applying forward post-adaptation non-linear response compression.
        // RGB_a = post_adaptation_non_linear_response_compression_forward(RGB_c, F_L)
        // RGB_a_l = d_post_adaptation_non_linear_response_compression_forward(
        //     full(3, L_B), F_L
        // ) * (
        //     RGB_c - L_B
        // ) + post_adaptation_non_linear_response_compression_forward(
        //     full(3, L_B), F_L
        // )
        // RGB_a = np.where(RGB_c < L_B, RGB_a_l, RGB_a)

        // # Step 3
        // # Applying forward post-adaptation non-linear response compression.
        float3 RGB_a = post_adaptation_non_linear_response_compression_forward(RGB_c, F_L);
        // float3 RGB_a = RGB_c;
        // float3 RGB_a_l = d_post_adaptation_non_linear_response_compression_forward(L_B, F_L) * ( RGB_c - L_B) + post_adaptation_non_linear_response_compression_forward( L_B, F_L );

        float3 RGB_a_l = d_post_adaptation_non_linear_response_compression_forward(
          L_B, F_L
          ) * (
          RGB_c - L_B
          ) + post_adaptation_non_linear_response_compression_forward(
          L_B, F_L
          );

        // float3 RGB_d;
        RGB_a.x = RGB_c.x < L_B.x ? RGB_a_l.x: RGB_a.x;
        RGB_a.y = RGB_c.y < L_B.y ? RGB_a_l.y: RGB_a.y;
        RGB_a.z = RGB_c.z < L_B.z ? RGB_a_l.z: RGB_a.z;




        // # Step 4
        // # Converting to preliminary cartesian coordinates.
        // R_a, G_a, B_a = tsplit(RGB_a)
        float R_a = RGB_a.x ;
        float G_a = RGB_a.y ;
        float B_a = RGB_a.z ;
        // a = R_a - 12 * G_a / 11 + B_a / 11
        float a = R_a - 12.0f * G_a / 11.0f + B_a / 11.0f;
        // b = (R_a + G_a - 2 * B_a) / 9
        float b = (R_a + G_a - 2.0f * B_a) / 9.0f;

        // # Computing the *hue* angle :math:`h`.
        // h = np.degrees(np.arctan2(b, a)) % 360
        // Unclear why this isnt matching the python version.
        float h = mod(degrees(atan2(b, a)), 360.0f);

        

        // # Step 5
        // # Computing eccentricity factor *e_t*.
        // hr = np.radians(h)
        float hr = radians(h);

        // _h = hr
        // _2_h = 2 * hr
        // _3_h = 3 * hr
        // _4_h = 4 * hr
        float _h = hr;
        float _2_h = 2 * hr;
        float _3_h = 3 * hr;
        float _4_h = 4 * hr;

        // e_t = (
        //     -0.0582 * np.cos(_h)
        //     - 0.0258 * np.cos(_2_h)
        //     - 0.1347 * np.cos(_3_h)
        //     + 0.0289 * np.cos(_4_h)
        //     - 0.1475 * np.sin(_h)
        //     - 0.0308 * np.sin(_2_h)
        //     + 0.0385 * np.sin(_3_h)
        //     + 0.0096 * np.sin(_4_h)
        //     + 1
        // )
        float e_t = (
            -0.0582f * cos(_h)
            - 0.0258f * cos(_2_h)
            - 0.1347f * cos(_3_h)
            + 0.0289f * cos(_4_h)
            - 0.1475f * sin(_h)
            - 0.0308f * sin(_2_h)
            + 0.0385f * sin(_3_h)
            + 0.0096f * sin(_4_h)
            + 1.0f
        );

        // # Step 6
        // # Computing achromatic responses for the stimulus.
        // R_a, G_a, B_a = tsplit(RGB_a)
        float R_a2 = RGB_a.x ;
        float G_a2 = RGB_a.y ;
        float B_a2 = RGB_a.z ;
        // A = 2 * R_a + G_a + 0.05 * B_a - 0.305
        float A = 2 * R_a2 + G_a2 + 0.05f * B_a2 - 0.305f;

        // # Step 7
        // # Computing the correlate of *Lightness* :math:`J`.
        // with sdiv_mode():
        //     J = 100 * spow(sdiv(A, A_w), surround.c * z)

        float J = 100.0f * spow(sdiv(A, A_w), surround.y * z);

        // # Step 8
        // # Computing the correlate of *brightness* :math:`Q`.
        // with sdiv_mode():
        //     Q = (2 / as_float(surround.c)) * (J / 100) * A_w
        float Q = (2.0f / float(surround.y)) * (J / 100.0f) * A_w;

        // # Step 9
        // # Computing the correlate of *colourfulness* :math:`M`.
        // M = 43 * surround.N_c * e_t * np.sqrt(a**2 + b**2)
        float M = 43.0f * surround.z * e_t * sqrt(a * a + b * b);

        // # Computing the correlate of *chroma* :math:`C`.
        // with sdiv_mode():
        //     C = 35 * sdiv(M, A_w)
        float C = 35.0f * sdiv(M, A_w);


        // # Computing the correlate of *saturation* :math:`s`.
        // with sdiv_mode():
        //     s = 100 * sdiv(M, Q)
        float s = 100.0f * sdiv(M, Q);

        // # *Helmholtzâ€“Kohlrausch* Effect Extension.
        float J_HK = J + hue_angle_dependency_Hellwig2022(hr) * spow(C, 0.587f);
        float Q_HK = (2.0f / surround.y) * (J_HK / 100.0f) * A_w ;
    
        // return XYZ_w;
        // return RGB_w;
        // return {D,k,k4};
        // return {F_L,n,z};
        // return RGB_c;
        if (HK_mode)
        {
          return {J_HK,M,h};
        }
        else
        {
          return {J,M,h};
        }
        // return XYZ;
    }

    float3 Hellwig2022_linearExtension_JMh_to_XYZ( float3 JMh, float3 XYZ_w, float L_A, float Y_b, float3 surround, bool discount_illuminant)
    {
        float J = JMh.x;
        float M = JMh.y;
        float h = JMh.z;

  
        // L_A = as_float_array(L_A)
        // XYZ_w = to_domain_100(XYZ_w)
        // _X_w, Y_w, _Z_w = tsplit(XYZ_w)
        float _X_w = XYZ_w.x;
        float Y_w = XYZ_w.y;
        float _Z_w = XYZ_w.z;

        // # Step 0
        // # Converting *CIE XYZ* tristimulus values to sharpened *RGB* values.
        // RGB_w = vector_dot(MATRIX_16, XYZ_w)
        float3x3 MATRIX_16 = CAT_CAT16;
        float3 RGB_w = vector_dot(MATRIX_16, XYZ_w);


        // # Computing degree of adaptation :math:`D`.
        float D = clip(degree_of_adaptation(surround.x, L_A), 0, 1);
        if(discount_illuminant)
        {
            D = 1.0f;
        }



        // # Viewing conditions dependent parameters
        float k = 1 / (5 * L_A + 1);
        float k4 = pow(k,4);
        float F_L = 0.2f * k4 * (5.0f * L_A) + 0.1f * pow((1.0f - k4), 2.0f) * spow(5.0f * L_A, 1.0f / 3.0f) ;
        float n = sdiv(Y_b, Y_w);
        float z = 1.48 + sqrt(n);

        // // float D_RGB = ( D[..., np.newaxis] * Y_w[..., np.newaxis] / RGB_w + 1 - D[..., np.newaxis] )
        float3 D_RGB = D * Y_w / RGB_w + 1 - D;
        float3 RGB_wc = D_RGB * RGB_w;
        
        // # Applying forward post-adaptation non-linear response compression.
        // F_L_RGB = spow(F_L[..., np.newaxis] * np.absolute(RGB_wc) / 100, 0.42)
        float3 F_L_RGB = float3spow(F_L * float3abs(RGB_wc) / 100.0f, 0.42f);

        // # Computing achromatic responses for the whitepoint.
        // RGB_aw = (400 * np.sign(RGB_wc) * F_L_RGB) / (27.13 + F_L_RGB) + 0.1
        float3 RGB_aw = (400.0f * float3sign(RGB_wc) * F_L_RGB) / (27.13f + F_L_RGB) + 0.1f;

        // # Computing achromatic responses for the whitepoint.
        // R_aw, G_aw, B_aw = tsplit(RGB_aw)
        float R_aw = RGB_aw.x ;
        float G_aw = RGB_aw.y ;
        float B_aw = RGB_aw.z ;
        // A_w = 2 * R_aw + G_aw + 0.05 * B_aw - 0.305
        float A_w = 2 * R_aw + G_aw + 0.05f * B_aw - 0.305f;

        // # Step 2
        // # Computing eccentricity factor *e_t*.
        // hr = np.radians(h)
        float hr = radians(h);


        // # *Helmholtzâ€“Kohlrausch* Effect Extension.
        float C = (M * 35) / A_w;
         
        if (HK_mode)
        {
          J = J - hue_angle_dependency_Hellwig2022(hr) * spow(C, 0.587f);
        }



        // _h = hr
        // _2_h = 2 * hr
        // _3_h = 3 * hr
        // _4_h = 4 * hr
        float _h = hr;
        float _2_h = 2 * hr;
        float _3_h = 3 * hr;
        float _4_h = 4 * hr;
    
        // e_t = (
        //     -0.0582 * np.cos(_h)
        //     - 0.0258 * np.cos(_2_h)
        //     - 0.1347 * np.cos(_3_h)
        //     + 0.0289 * np.cos(_4_h)
        //     - 0.1475 * np.sin(_h)
        //     - 0.0308 * np.sin(_2_h)
        //     + 0.0385 * np.sin(_3_h)
        //     + 0.0096 * np.sin(_4_h)
        //     + 1
        // )
        float e_t = (
            -0.0582f * cos(_h)
            - 0.0258f * cos(_2_h)
            - 0.1347f * cos(_3_h)
            + 0.0289f * cos(_4_h)
            - 0.1475f * sin(_h)
            - 0.0308f * sin(_2_h)
            + 0.0385f * sin(_3_h)
            + 0.0096f * sin(_4_h)
            + 1.0f
        );

        // # Computing achromatic response :math:`A` for the stimulus.
        // A = A = A_w * spow(J / 100, 1 / (surround.c * z))
        float A = A_w * spow(J / 100.0f, 1.0f / (surround.y * z));

        // # Computing *P_p_1* to *P_p_2*.
        // P_p_1 = 43 * surround.N_c * e_t
        // P_p_2 = A
        float P_p_1 = 43.0f * surround.z * e_t;
        float P_p_2 = A;


        // # Step 3
        // # Computing opponent colour dimensions :math:`a` and :math:`b`.
        // with sdiv_mode():
        //     gamma = M / P_p_1
        float gamma = M / P_p_1;
    
        // a = gamma * np.cos(hr)
        float a = gamma * cos(hr);
        // b = gamma * np.sin(hr)
        float b = gamma * sin(hr);


        // # Step 4
        // # Applying post-adaptation non-linear response compression matrix.
        // RGB_a = (
        //     vector_dot(
        //         [
        //             [460, 451, 288],
        //             [460, -891, -261],
        //             [460, -220, -6300],
        //         ],
        //         tstack([P_p_2, a, b]),
        //     )
        //     / 1403
        // )

        float panlrcm_data[]=
        {
            460.0f, 451.0f, 288.0f,
            460.0f, -891.0f, -261.0f,
            460.0f, -220.0f, -6300.0f,
        };
        float3x3 panlrcm;
        panlrcm.setArray(panlrcm_data);

        float3 RGB_a = vector_dot(panlrcm, float3(P_p_2, a, b)) / 1403.0f;

        // # Step 5
        // # Applying inverse post-adaptation non-linear response compression.
        // RGB_c = (
        //     np.sign(RGB_a)
        //     * 100
        //     / F_L[..., np.newaxis]
        //     * spow(
        //         (27.13 * np.absolute(RGB_a)) / (400 - np.absolute(RGB_a)),
        //         1 / 0.42,
        //     )
        // )
        // float3 RGB_c = float3sign(RGB_a) * 100.0f / F_L * float3spow((27.13f * float3abs(RGB_a)) / (400.0f - float3abs(RGB_a)), 1.0f / 0.42f);


        // # Step 5
        // # Applying inverse post-adaptation non-linear response compression.
        // RGB_c = post_adaptation_non_linear_response_compression_inverse(RGB_a, F_L)
        // RGB_c_l = (
        //     RGB_a
        //     - post_adaptation_non_linear_response_compression_forward(
        //         full(3, L_B), F_L
        //     )
        // ) / (
        //     d_post_adaptation_non_linear_response_compression_forward(
        //         full(3, L_B), F_L
        //     )
        // ) + L_B
        // RGB_c = np.where(RGB_c < L_B, RGB_c_l, RGB_c)

        // Adding 0.1 here seems to fix the inversion issue, not really clear on why I'm needing to do this
        // RGB_a = RGB_a + 0.1f;
        float3 RGB_c = post_adaptation_non_linear_response_compression_inverse(RGB_a + 0.1, F_L);
        // float3 RGB_c = RGB_a;
        float3 RGB_c_l = ( RGB_a + 0.1 - post_adaptation_non_linear_response_compression_forward( L_B, F_L)) / (d_post_adaptation_non_linear_response_compression_forward( L_B, F_L)) + L_B;

        float3 RGB_d;
        RGB_d.x = RGB_c.x < L_B.x ? RGB_c_l.x : RGB_c.x;
        RGB_d.y = RGB_c.y < L_B.y ? RGB_c_l.y : RGB_c.y;
        RGB_d.z = RGB_c.z < L_B.z ? RGB_c_l.z : RGB_c.z;


        // # Step 6
        // RGB = RGB_c / D_RGB
        float3 RGB = RGB_d / D_RGB;
        
    
        // # Step 7
        // XYZ = vector_dot(MATRIX_INVERSE_16, RGB)
        float3x3 MATRIX_INVERSE_16 = CAT_CAT16.invert();
        float3 XYZ = vector_dot(MATRIX_INVERSE_16, RGB);


        // return XYZ;
        return XYZ;

    }




  void init()
  {
    HALF_MIN = 0.0000000596046448f;
    HALF_MAX = 65504.0f;

    float CAT_CAT16_data[]=
    {
      0.401288, 0.650173, -0.051461,
      -0.250268, 1.204414, 0.045854,
      -0.002079, 0.048952, 0.953127,
    };

    float Modified_CAT16_data[]=
    {
      0.656619, 0.342071, 0.00131062,
      -0.222571, 1.10658, 0.115987,
      -0.000634146, 0.05855, 0.942084,
    };

    if (catDataSelection == 0)
    {
        CAT_CAT16.setArray(CAT_CAT16_data);
    }
    else if (catDataSelection == 1)
    {
        CAT_CAT16.setArray(Modified_CAT16_data);
    }
    else if (catDataSelection == 2)
    {
      CAT_CAT16 = RGBPrimsToXYZMatrix(rxy,gxy,bxy,wxy,1.0f,1);
    }


  }


  void process()
  {
    SampleType(src) source = src();
    float3 srcRGB(source.x, source.y, source.z);
    float3 dstRGB;
    float3 diagnostic;

    // diagnostic =  srcRGB;

    // float3 surround(1.0f, 0.69f, 1.0f);
    // float3 XYZ_w(95.05f, 100.00f, 108.88f);

    if (direction == 0)
    {
        float3 JMh = XYZ_to_Hellwig2022_linearExtension_JMh(srcRGB, XYZ_w, L_A, Y_b,surround,discount_illuminant);
        dstRGB = JMh;
    }
    else if (direction == 1)
    {
        float3 XYZ_out = Hellwig2022_linearExtension_JMh_to_XYZ(srcRGB, XYZ_w, L_A, Y_b, surround, discount_illuminant);
        dstRGB = XYZ_out;
    }
    else if (direction == 2)
    {

      dstRGB = srcRGB;
    }
    else if (direction == 3)
    {
        float3 compressed = post_adaptation_non_linear_response_compression_forward(srcRGB,L_A);
        float3 uncompressed = post_adaptation_non_linear_response_compression_inverse(compressed,L_A);
        dstRGB = uncompressed;
    }
    else if (direction == 4)
    {
        float3 JMh =     XYZ_to_Hellwig2022_linearExtension_JMh(srcRGB, XYZ_w, L_A, Y_b, surround, discount_illuminant);
        float3 XYZ_out = Hellwig2022_linearExtension_JMh_to_XYZ(JMh   , XYZ_w, L_A, Y_b, surround, discount_illuminant);
        dstRGB = XYZ_out;
    }
    else if (direction == 5)
    { 
      float angle = hue_angle_dependency_Hellwig2022(srcRGB.x);
      dstRGB = float3(angle,angle,angle);
    }


    diagnostic = dstRGB;


    dst() = float4(diagnostic.x, diagnostic.y, diagnostic.z, source.w ); 
  }
};
